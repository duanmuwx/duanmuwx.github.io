<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="论文复现的学习之路 论文 [Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter](..\papers\车辆路径修正\Generic Vehicle Tracking Framework Capable of Handling Occlu">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2021/05/06/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="论文复现的学习之路 论文 [Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter](..\papers\车辆路径修正\Generic Vehicle Tracking Framework Capable of Handling Occlu">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://www.guyuehome.com/Uploads/wp/2020/06/48.png">
<meta property="og:image" content="https://www.guyuehome.com/Uploads/wp/2020/06/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20200603145143-300x236.png">
<meta property="og:image" content="https://miro.medium.com/max/1047/1*uRpfceAICGl10qRz2VvaBg.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-77b78405273672540fcf1abfff58f396_720w.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1042406/201703/1042406-20170327143755811-993574578.png">
<meta property="article:published_time" content="2021-05-06T11:40:53.227Z">
<meta property="article:modified_time" content="2021-08-05T07:44:45.510Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.guyuehome.com/Uploads/wp/2020/06/48.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-复现论文的学习之路" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/05/06/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" class="article-date">
  <time class="dt-published" datetime="2021-05-06T11:40:53.227Z" itemprop="datePublished">2021-05-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>论文复现的学习之路</p>
<h1 id="论文-Generic-Vehicle-Tracking-Framework-Capable-of-Handling-Occlusions-Based-on-Modified-Mixture-Particle-Filter-papers-车辆路径修正-Generic-Vehicle-Tracking-Framework-Capable-of-Handling-Occlusions-pdf"><a href="#论文-Generic-Vehicle-Tracking-Framework-Capable-of-Handling-Occlusions-Based-on-Modified-Mixture-Particle-Filter-papers-车辆路径修正-Generic-Vehicle-Tracking-Framework-Capable-of-Handling-Occlusions-pdf" class="headerlink" title="论文 [Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter](..\papers\车辆路径修正\Generic Vehicle Tracking Framework Capable of Handling Occlusions.pdf)"></a>论文 [Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter](..\papers\车辆路径修正\Generic Vehicle Tracking Framework Capable of Handling Occlusions.pdf)</h1><p>$$<br>predict: \quad \int D(x_t|x_{t-1})p(dx_{t-1}|y^{t-1}) \<br>update: \quad \frac{L(y_t|x_t)p(x_t|y^{t-1})}{\int L(y_t|s_t)p(ds_t|y^{t-1})}<br>$$</p>
<h2 id="对论文的理解"><a href="#对论文的理解" class="headerlink" title="对论文的理解"></a>对论文的理解</h2><ul>
<li><p><input disabled="" type="checkbox">  recursive Bayesian state estimation and mixture model representation, 论文 [Maintaining multimodality through mixture tracking](..\papers\车辆路径修正\Maintaining multimodality through mixture tracking.pdf)</p>
<p>$\pi_{m,k}$ is mixture wieght for the m-th component at time step $t$ and $\sum_{m=1}^M \pi_{m,t}=1$</p>
<p>The particle<br>representation implies a Monte Carlo approximation of the mixture filtering distribution of the form<br>$$<br>p(x_t|y^t)=\sum_{m=1}^M \pi_{m,t}\sum_{i \in I_m} w_t^{(i)}\delta_{x_t^{(t)}}(x_t)<br>$$</p>
<blockquote>
<p>The particle filter is a Monte Carlo method that represents the target distribution with a weighted set of samples that are propagated in such a manner so as to maintain a properly weighted sample from the target distribution at subsequent time steps.</p>
</blockquote>
<p>$c_t^{(i)}=m$ if particle $i$ belongs to mixture component $m$. </p>
</li>
</ul>
<p>Bayesian state estimation and mixtu  re model representation</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/varyshare/article/details/97642209">易懂教程我是如何十分钟理解与推导贝叶斯滤波(Bayes Filter)算法？</a></p>
</blockquote>
<p>Bayes公式</p>
<p><img src="https://www.guyuehome.com/Uploads/wp/2020/06/48.png" alt="https://www.guyuehome.com/Uploads/wp/2020/06/48.png"></p>
<p>延伸出的公式</p>
<p><img src="https://www.guyuehome.com/Uploads/wp/2020/06/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20200603145143-300x236.png" alt="https://www.guyuehome.com/Uploads/wp/2020/06/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20200603145143-300x236.png"></p>
<p>理解了上面两张图片中的公式就理解了论文中的 <strong>Prior Update</strong>, <strong>Measurement Update</strong>.</p>
<h3 id="Gaussian-mixture-model-as-the-prediction-model"><a href="#Gaussian-mixture-model-as-the-prediction-model" class="headerlink" title="Gaussian mixture model as the prediction model"></a>Gaussian mixture model as the prediction model</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Kuo_Jun_Lin/article/details/115415884">高斯混合模型还能这样预测新冠发病人数与位置</a></p>
<p>该论文引用的论文： [A probabilistic long term prediction approach for highway scenarios](..\papers\车辆路径修正\A probabilistic long term prediction approach for highway scenarios.pdf) </p>
<p>论文 高斯混合模型做轨迹预测： [Probabilistic trajectory prediction with gaussian mixture models](..\papers\车辆路径修正\Probabilistic trajectory prediction with gaussian mixture models.pdf) </p>
<p><a target="_blank" rel="noopener" href="https://github.com/AlexanderFabisch/gmr/blob/master/examples/plot_trajectories.py">GMR 轨迹回归</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/ceteke/GMM-GMR">This repository contains the implementation of GMM-GMR based imitation learning from multiple trajectories.</a></p>
<h2 id="论文中涉及到的知识点"><a href="#论文中涉及到的知识点" class="headerlink" title="论文中涉及到的知识点"></a>论文中涉及到的知识点</h2><h3 id="粒子滤波算法及原理"><a href="#粒子滤波算法及原理" class="headerlink" title="粒子滤波算法及原理"></a>粒子滤波算法及原理</h3><ul>
<li>The idea of the particle filter (PF: Particle Filter) is based on <em>Monte Carlo methods</em>, which use particle sets to represent probabilities and can be used in any form of state space model. </li>
<li> The core idea is to express its distribution by extracting random state particles from the posterior probability. It is a sequential importance sampling method (Sequential Importance Sampling).</li>
<li><img src="https://miro.medium.com/max/1047/1*uRpfceAICGl10qRz2VvaBg.png" alt="img" style="zoom: 50%;" /></li>
<li>Although the probability distribution in the algorithm is only an  approximation of the real distribution, due to the non-parametric  characteristics, it can get rid of the constraint that the random  quantity must satisfy the Gaussian distribution when solving the  nonlinear filtering problem, and can express a wider distribution than  the Gaussian model.</li>
</ul>
<blockquote>
<p>Particle filters methods are recursive Bayesian filters which provide a  convenient and attractive approach to approximate the posterior  distributions when the model is nonlinear and when the noises are not  Gaussian.</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/pSCE3hn6jsqq11NC0rK5mw">什么是粒子滤波</a></p>
<blockquote>
<ul>
<li>重要性采样（IS）</li>
<li>序列重要性采样和重采样（SIS）</li>
</ul>
<p>粒子滤波就是<strong>“序列重要性采样+重采样”</strong>的结果</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/piaoxuezhong/article/details/78619150">从原理到实现讲解粒子滤波</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/rhymesg/Particle_Filter"><code>mixture particle filter</code> github 实现</a></p>
<p>通俗理解SLAM算法</p>
<blockquote>
<p>SLAM (simultaneous localization and mapping),也称为CML (Concurrent Mapping and Localization), 即时定位与地图构建，或并发建图与定位。问题可以描述为：将一个机器人放入未知环境中的未知位置，是否有办法让机器人一边逐步描绘出此环境完全的地图，同时一边决定机器人应该往哪个方向行进。例如扫地机器人就是一个很典型的SLAM问题，所谓完全的地图（a consistent map）是指不受障碍行进到房间可进入的每个角落。SLAM最早由Smith、Self和Cheeseman于1988年提出。由于其重要的理论与应用价值，被很多学者认为是实现真正全自主移动机器人的关键。</p>
<p>当你来到一个陌生的环境时，为了迅速熟悉环境并完成自己的任务（比如找饭馆，找旅馆），你应当做以下事情： a.用眼睛观察周围地标如建筑、大树、花坛等，并记住他们的特征（特征提取） b.在自己的脑海中，根据双目获得的信息，把特征地标在三维地图中重建出来（三维重建） c.当自己在行走时，不断获取新的特征地标，并且校正自己头脑中的地图模型（bundle adjustment or EKF） d.根据自己前一段时间行走获得的特征地标，确定自己的位置（trajectory） e.当无意中走了很长一段路的时候，和脑海中的以往地标进行匹配，看一看是否走回了原路（loop-closure detection）。实际这一步可有可无。 以上五步是同时进行的，因此是simultaneous localization and mapping.</p>
</blockquote>
<p>粒子滤波面临的问题</p>
<blockquote>
<p>Although the particle filter algorithm can be used as an effective means to  solve the SLAM problem, there are still some problems in the algorithm.  The main problem is that a large number of samples are needed to closely approximate the posterior probability density of the system. The more  complex the environment the robot faces, the more samples are needed to  describe the posterior probability distribution, and the more complex  the algorithm.</p>
<p>Therefore, an adaptive sampling strategy that can effectively reduce the number of samples is the focus of the algorithm. In addition, the re-sampling  phase can result in loss of sample validity and diversity, leading to  sample depletion. How to maintain the validity and diversity of  particles and overcome the depletion of samples is also re-sampling the  focus of this algorithm.</p>
</blockquote>
<h3 id="马尔可夫链蒙特卡洛方法"><a href="#马尔可夫链蒙特卡洛方法" class="headerlink" title="马尔可夫链蒙特卡洛方法"></a>马尔可夫链蒙特卡洛方法</h3><h4 id="图文解读什么是马尔可夫链蒙特卡罗方法"><a href="#图文解读什么是马尔可夫链蒙特卡罗方法" class="headerlink" title="图文解读什么是马尔可夫链蒙特卡罗方法"></a><a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2017-12-24-6">图文解读什么是马尔可夫链蒙特卡罗方法</a></h4><p>简单地说</p>
<blockquote>
<p>MCMC方法是用来在概率空间，通过随机采样估算兴趣参数的后验分布。</p>
</blockquote>
<img src="https://pic3.zhimg.com/80/v2-77b78405273672540fcf1abfff58f396_720w.jpg" alt="img" style="zoom: 33%;" />

<p>红色的曲线代表后验分布。你可以把它看作先验分布和可能性分布的平均值。由于先验分布较短且分散，所以它反映了人们并不太确定人类的平均身高是多少。同时，可能性在相对较窄的范围内汇总了数据，因此它对真是参数值更加确定。</p>
<p>当先验分布和可能性分布被合并时，数据（由可能性表示）支配了之前那个在巨人堆里长大的人的弱先验信念。尽管那一个体仍然认为人类平均身高比数据告诉他的稍高些，但他最相信的是数据。</p>
<p>存在一些后验分布给出了每个参数值的可能性。但是很难看出完整的分布，也无法用分析解决。于是这就需要MCMC方法了。</p>
<p>MCMC允许我们估计后验分布的形状，以防我们无法直接计算。</p>
<p><strong>马尔可夫链</strong></p>
<blockquote>
<p>举一个更有用的例子。假如你的房子有五个房间，分别是卧室、卫生间、客厅、餐厅和厨房。让我们收集一些数据，假设不管你在任何时候处于任何房间，我们都能推测出你下一个可能进入的房间，例如，如果你在厨房，你将有30%的可能性留在厨房，30%的可能性进入餐厅，20%的可能性进入客厅，10%的可能性进入卧室，然后有10%的可能性去到卫生间。利用每个房间的一组概率，我们可以构建一个“你将去到的房间”链。</p>
<p>如果我们想要预测这个人在离开厨房后会在哪个房间中待一小会儿的概率，那么做一些预测是有用的。但是由于我们的预测只是基于对房间里一个人的观察，所以有理由认为这种预测表现的不会很好。例如，假设一个人从卧室出来后进入了卫生间，那么他更有可能直接回到卧室。但如果是从厨房出来的话，就不一定回到卧室了。所以马尔科夫的成果不一定适用于现实世界。</p>
<p>然而，将马尔可夫链进行数千次迭代后，确实能够长期预测你可能会进入那个房间。更重要的是，这个预测并没有受到这人最初处于哪个房间的影响！简单地说：在某一时间某人处于家里哪个位置并不重要。所以马尔可夫链这个看似在几个时期内对随机变量建模的不合理方法，可以用来计算该变量的长期趋势。</p>
</blockquote>
<h4 id="刘建平MCMC"><a href="#刘建平MCMC" class="headerlink" title="刘建平MCMC"></a><a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6625739.html">刘建平MCMC</a></h4><ol>
<li>蒙特卡洛方法</li>
</ol>
<p>$$<br>不懂 \quad \theta = \int_a^b f(x)dx =  \int_a^b \frac{f(x)}{p(x)}p(x)dx \approx \frac{1}{n}\sum\limits_{i=0}^{n-1}\frac{f(x_i)}{p(x_i)}<br>$$</p>
<ol start="2">
<li><p>接收-拒绝采样</p>
<p>对于概率分布不是常见的分布，一个可行的办法是采用接受-拒绝采样来得到该分布的样本。既然 <em>p</em>(<em>x</em>) 太复杂在程序中没法直接采样，那么我设定一个程序可采样的分布 <em>q</em>(<em>x</em>) 比如高斯分布，然后按照一定的方法拒绝某些样本，以达到接近 <em>p</em>(<em>x</em>) 分布的目的，其中<em>q</em>(<em>x</em>)叫做 proposal distribution。</p>
<p><img src="https://images2015.cnblogs.com/blog/1042406/201703/1042406-20170327143755811-993574578.png" alt="img"></p>
<p>具体采用过程如下，设定一个方便采样的常用概率分布函数 <em>q</em>(<em>x</em>)，以及一个常量 <em>k</em>，使得 <em>p</em>(<em>x</em>) 总在 kq(<em>x</em>) 的下方。如上图。首先，采样得到<em>q</em>(<em>x</em>)的一个样本$z_0$，采样方法如第三节。然后，从均匀分布（0,<em>k</em> <em>q</em>(<em>z</em>0))中采样得到一个值<em>u</em>。如果<em>u</em>落在了上图中的灰色区域，则拒绝这次抽样，否则接受这个样本<em>z</em>0。重复以上过程得到n个接受的样本$z_0,z_1,…z_ {n−1}$, 整个过程中，我们通过一系列的接受拒绝决策来达到用<em>q</em>(<em>x</em>)模拟<em>p</em>(<em>x</em>)概率分布的目的。</p>
</li>
<li><p>马尔可夫链</p>
<blockquote>
<p>　总结下基于马尔科夫链的采样过程：</p>
<p>　1）输入马尔科夫链状态转移矩阵P，设定状态转移次数阈值<em>n</em>1，需要的样本个数<em>n</em>2</p>
<p>　2）从任意简单概率分布采样得到初始状态值<em>x</em>0</p>
<p>　3）for <em>t</em>=0 to n_1+n_2−1: 从条件概率分布<em>P</em>(<em>x</em>|xt)中采样得到样本x_t+1 样本集$(x_{n_1}, x_{n_1+1},…, x_{n_1+n_2-1})$</p>
<p>　即为我们需要的平稳分布对应的样本集。</p>
</blockquote>
<p>如果假定我们可以得到我们需要采样样本的平稳分布所对应的马尔科夫链状态转移矩阵，那么我们就可以用马尔科夫链采样得到我们需要的样本集，进而进行蒙特卡罗模拟。但是一个重要的问题是，随意给定一个平稳分布<em>π</em>,如何得到它所对应的马尔科夫链状态转移矩阵P呢？这是个大问题。我们绕了一圈似乎还是没有解决任意概率分布采样样本集的问题。幸运的是，MCMC采样通过迂回的方式解决了上面这个大问题，我们在下一篇来讨论MCMC的采样，以及它的使用改进版采样: M-H采样和Gibbs采样.</p>
</li>
<li><p>MCMC采样</p>
<blockquote>
<p>　1）输入我们任意选定的马尔科夫链状态转移矩阵<em>Q</em>，平稳分布<em>π</em>(<em>x</em>)，设定状态转移次数阈值<em>n</em>1，需要的样本个数<em>n</em>2</p>
<p>　2）从任意简单概率分布采样得到初始状态值<em>x</em>0</p>
<p>　3）for <em>t</em>=0  to <em>n</em>1+<em>n</em>2−1: </p>
<blockquote>
<p>a) 从条件概率分布<em>Q</em>(<em>x</em>|x_t)中采样得到样本x<br>b) 从均匀分布采样<em>u</em>∼uniform(0,1)<br>c) 如果$u &lt; \alpha(x_t,x_{<em>}) = \pi(x_{</em>})Q(x_{*},x_t)$, 则接受转移x_t→x，即x_t+1=x</p>
<blockquote>
</blockquote>
<p>d) 否则不接受转移，即x_{t+1}=x_t</p>
</blockquote>
<p>　样本集$(x_{n_1}, x_{n_1+1},…, x_{n_1+n_2-1})$即为我们需要的平稳分布对应的样本集。</p>
</blockquote>
<p>但存在收敛慢的情况，就是上面这个$n_1$非常大，这时就轮到 M-H采样出场了。</p>
<p><strong>Q&amp;A:</strong></p>
<blockquote>
<p>平稳分布（或者对应的条件分布）是需要事先知道的，只是很多平稳分布虽然我们知道其分布形式，但是没有好的方法采用这个平稳分布的样本集，所以才需要MCMC。</p>
<p>我们MCMC的目标是不断迭代逐渐达到平稳，使采集到的样本近似符合平稳分布。所以不存在你说的“一开始拿不到平稳分布”的情况。连分布都不知道，是没法用MCMC采样的。</p>
</blockquote>
</li>
<li><p>M-H采样</p>
<p>接收率 $\alpha$ 做了如下改进<br>$$<br>\alpha(i,j) = min{ \frac{\pi(j)Q(j,i)}{\pi(i)Q(i,j)},1}<br>$$</p>
</li>
<li><p>Gibbs采样</p>
<p>但是M-H采样有两个缺点：一是需要计算接受率，在高维时计算量大。并且由于接受率的原因导致算法收敛时间变长。二是有些高维数据，特征的条件概率分布好求，但是特征的联合分布不好求。因此需要一个好的方法来改进M-H采样，这就是我们下面讲到的Gibbs采样。<br>$$<br>P(A \to B) = \pi(x_2^{(B)}|x_1^{(1)});; if; x_1^{(A)} = x_1^{(B)} =x_1^{(1)}\<br>P(A \to C) = \pi(x_1^{(C)}|x_2^{(1)});; if; x_2^{(A)} = x_2^{(C)} =x_2^{(1)}\<br>P(A \to D) = 0;; else<br>$$<br>二维Gibbs采样过程如下</p>
<blockquote>
<p>利用上一节找到的状态转移矩阵，我们就得到了二维Gibbs采样，这个采样需要两个维度之间的条件概率。具体过程如下：</p>
<p>1）输入平稳分布$\pi(x_1,x_2)$，设定状态转移次数阈值$n_1$，需要的样本个数$n_2$</p>
<p>2）随机初始化初始状态值$x_1^{(0)}$和$x_2^{(0)}$</p>
<p>3）for <em>t</em>=0 to $n_1+n_2-1$: </p>
<blockquote>
<p>a) 从条件概率分布$P(x_2|x_1^{(t)})$中采样得到样本$x_2^{t+1}$</p>
<p>b) 从条件概率分布$P(x_1|x_2^{(t+1)})$中采样得到样本$x_1^{(t+1)}$</p>
<p>样本集${(x_1^{(n_1)}, x_2^{(n_1)}), (x_1^{(n_1+1)}, x_2^{(n_1+1)}), …,  (x_1^{(n_1+n_2-1)}, x_2^{(n_1+n_2-1)})}$即为我们需要的平稳分布对应的样本集。</p>
</blockquote>
<p>整个采样过程中，我们通过轮换坐标轴，采样的过程为：</p>
<p>$(x_1^{(1)}, x_2^{(1)}) \to  (x_1^{(1)}, x_2^{(2)}) \to (x_1^{(2)}, x_2^{(2)}) \to … \to (x_1^{(n_1+n_2-1)}, x_2^{(n_1+n_2-1)})$</p>
</blockquote>
<p>多维Gibbs采样过程类似</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/05/06/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" data-id="ckto3u195000720ia4bywdy5z" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/05/08/20210508_%E5%85%A5%E8%81%8C%E4%BB%A5%E6%9D%A5%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2021/04/25/Sort%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/08/09/pcap%E5%8C%85%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95%E7%BD%91%E5%9D%80/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/07/28/%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%AE%B0/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/07/15/2017%E5%B9%B4%E6%9D%A5%E7%9B%B8%E5%85%B3%E7%9A%843D%E8%A7%86%E8%A7%89%E7%82%B9%E4%BA%91%E7%AE%97%E6%B3%95%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/06/16/%E5%86%85%E5%A4%96%E5%8F%82%E6%A0%87%E5%AE%9A/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/06/07/%E9%9A%A7%E9%81%93%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>