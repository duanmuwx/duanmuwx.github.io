<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-pcap包安装方法网址" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/09/pcap%E5%8C%85%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95%E7%BD%91%E5%9D%80/" class="article-date">
  <time class="dt-published" datetime="2021-08-09T08:45:01.363Z" itemprop="datePublished">2021-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="安海洋"><a href="#安海洋" class="headerlink" title="安海洋"></a>安海洋</h2><p><a target="_blank" rel="noopener" href="https://www.litreily.top/2018/12/31/pypcap-install/">https://www.litreily.top/2018/12/31/pypcap-install/</a></p>
<p><a target="_blank" rel="noopener" href="https://pypi.org/project/pypcap/#files">https://pypi.org/project/pypcap/#files</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42525106/article/details/112031579">https://blog.csdn.net/weixin_42525106/article/details/112031579</a></p>
<p>pcap.c<br>C:\ProgramData\Anaconda3\include\pyconfig.h(59): fatal error C1083: 无法打开包括文件: “io.h”: No such file or directory<br>error: command ‘D:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\bin\HostX86\x64\cl.exe’ failed with exit status 2</p>
<h2 id="端木"><a href="#端木" class="headerlink" title="端木-"></a>端木-</h2><h3 id="解决安装-pypcap（Windows系统）"><a href="#解决安装-pypcap（Windows系统）" class="headerlink" title="解决安装 pypcap（Windows系统）"></a>解决安装 pypcap（Windows系统）</h3><p>使用 <code>pip install pcap</code>命令遇到的问题</p>
<blockquote>
<p>报错 <code>pcap.h not found</code></p>
<p>以及之后出现的一大片红色错误</p>
</blockquote>
<p><strong>解决方法</strong></p>
<p><a target="_blank" rel="noopener" href="https://nmap.org/npcap/#download">https://nmap.org/npcap/#download</a> 安装<code>Npcap</code> 并下载<code>Npcap SDK</code></p>
<p>找到里面的Include和Lib，分别将里面的内容复制到anaconda 安装目录中的对应文件夹中Include, 以及 libs去。</p>
<p>注意复制Lib中有个64位版本的<code>X64</code>文件夹。复制哪个应该是取决于操作系统（未测试）</p>
<p><strong>参考资料</strong></p>
<ol>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/Mengchangxin/p/9494489.html"><a target="_blank" rel="noopener" href="https://www.cnblogs.com/Mengchangxin/p/9494489.html">Windows下安装使用Pypcap</a></a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/PARKED/article/details/91545830">windows下安装并使用python+pypcap+dpkt抓取IP数据包并分析</a></p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/09/pcap%E5%8C%85%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95%E7%BD%91%E5%9D%80/" data-id="ckto3u192000320iadnmm5ez5" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-学习杂记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/07/28/%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2021-07-28T07:42:47.266Z" itemprop="datePublished">2021-07-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="AD算法项目"><a href="#AD算法项目" class="headerlink" title="AD算法项目"></a>AD算法项目</h1><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ol>
<li><p>采样率</p>
<blockquote>
<p><strong>采样率</strong>（也称为<strong>采样速度</strong>或者<strong>采样频率</strong>）定义了每秒从<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BF%9E%E7%BB%AD%E4%BF%A1%E5%8F%B7">连续信号</a>中提取并组成<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A6%BB%E6%95%A3%E4%BF%A1%E5%8F%B7">离散信号</a>的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%87%87%E6%A0%B7">采样</a>个数，它用<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%B5%AB%E5%85%B9">赫兹</a>（Hz）来表示。采样频率的倒数叫作<strong>采样周期</strong>或<strong>采样时间</strong>，它是<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%87%87%E6%A0%B7">采样</a>之间的时间间隔。</p>
</blockquote>
</li>
<li><p>时间单位</p>
<p><img src="https://i.loli.net/2021/08/17/E1CNBZMpOivujQ8.png" alt="图片.png"></p>
</li>
<li><p>虚拟串口</p>
</li>
<li><p>波特率</p>
<blockquote>
<p>在电子通信领域，波特（Baud）即调制速率，指的是有效数据讯号调制载波的速率，即单位时间内载波调制状态变化的次数。</p>
<p>波特率表示单位时间内传送的<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E7%A0%81%E5%85%83/10525003">码元</a>符号的个数，它是对符号传输速率的一种度量，它用单位时间内<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E8%BD%BD%E6%B3%A2/3441949">载波</a>调制状态改变的次数来表示，波特率即指一个单位时间内传输符号的个数。</p>
</blockquote>
</li>
</ol>
<h2 id="Pyserial"><a href="#Pyserial" class="headerlink" title="Pyserial"></a>Pyserial</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/caiya/p/13136785.html">python–serial串口通信</a></p>
<h2 id="PyQt"><a href="#PyQt" class="headerlink" title="PyQt"></a>PyQt</h2><ol>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/jia666666/article/details/81534260">QComboBox</a></p>
</li>
<li><p><a href="">QSpinBox</a> </p>
<p>QSPINBox是一个计数器控件，允许用户选择一个整数值通过单击向上向下或者按键盘上的上下键来增加减少当前显示的值，当然用户也可以输入值</p>
</li>
<li><p>QGridLayout</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/jia666666/article/details/81701176">https://blog.csdn.net/jia666666/article/details/81701176</a></p>
</li>
<li><p>serial.tools.list_ports_windows.comports()</p>
<p>返回计算机上所有的port口信息</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_29666899/article/details/79118404">QtCore.QTimer()</a></p>
<p>当代程序中需要显示时间时或者需要在程序中周期性地进行某项操作，就会用到定时器。PyQt5就提供了一个定时器QTimer来实现这种操作 </p>
</li>
</ol>
<h2 id="信号处理"><a href="#信号处理" class="headerlink" title="信号处理"></a>信号处理</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/80625865">信号处理-卷积</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/22298352">如何通俗易懂地解释卷积？</a></p>
<h4 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h4><p><a target="_blank" rel="noopener" href="https://www.matongxue.com/madocs/473">如何通俗地理解傅立叶变换？</a></p>
<p><a target="_blank" rel="noopener" href="https://www.matongxue.com/madocs/712">从傅立叶级数到傅立叶变换</a></p>
<p><a target="_blank" rel="noopener" href="https://www.acwing.com/file_system/file/content/whole/index/content/1563813/">【学习笔记】超简单的快速傅里叶变换（FFT）（含全套证明）</a></p>
<h4 id="python-信号处理"><a href="#python-信号处理" class="headerlink" title="python 信号处理"></a>python 信号处理</h4><p><a target="_blank" rel="noopener" href="https://wizardforcel.gitbooks.io/hyry-studio-scipy/content/20.html">频域信号处理</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/HolyShine/p/10445067.html">Python中的音频和数字信号处理（DSP）</a></p>
<h1 id="深度学习学习杂记"><a href="#深度学习学习杂记" class="headerlink" title="深度学习学习杂记"></a>深度学习学习杂记</h1><h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><h3 id="Inception块"><a href="#Inception块" class="headerlink" title="Inception块"></a>Inception块</h3><p><img src="https://zh-v2.d2l.ai/_images/inception.svg" alt="../_images![../_images/inception.svg](https://zh-v2.d2l.ai/_images/inception.svg)/inception.svg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inception</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># `c1`--`c4` 是每条路径的输出通道数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, c1, c2, c3, c4, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__(**kwargs)</span><br><span class="line">        <span class="comment"># 线路1，单1 x 1卷积层</span></span><br><span class="line">        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 线路2，1 x 1卷积层后接3 x 3卷积层</span></span><br><span class="line">        self.p2_1 = nn.Conv2d(in_channels, c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p2_2 = nn.Conv2d(c2[<span class="number">0</span>], c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 线路3，1 x 1卷积层后接5 x 5卷积层</span></span><br><span class="line">        self.p3_1 = nn.Conv2d(in_channels, c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p3_2 = nn.Conv2d(c3[<span class="number">0</span>], c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 线路4，3 x 3最大汇聚层后接1 x 1卷积层</span></span><br><span class="line">        self.p4_1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        p1 = F.relu(self.p1_1(x))</span><br><span class="line">        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))</span><br><span class="line">        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))</span><br><span class="line">        p4 = F.relu(self.p4_2(self.p4_1(x)))</span><br><span class="line">        <span class="comment"># 在通道维度上连结输出</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="残差网络的解释"><a href="#残差网络的解释" class="headerlink" title="残差网络的解释"></a>残差网络的解释</h3><img src="https://i.loli.net/2021/08/11/hp7lGETUAtnQqWc.png" alt="image-20210810154203168.png" style="zoom:67%;" />

<blockquote>
<p>因此，只有当较复杂的函数类包含较小的函数类时，我们才能确保提高它们的性能。 对于深度神经网络，如果我们能将新添加的层训练成 <em>恒等映射</em>（identity function） $f(x)=x$​ ，新模型和原模型将同样有效。 同时，由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差。</p>
</blockquote>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/40050371">一文读懂卷积神经网络中的1 x 1卷积核</a></p>
<ul>
<li>对于同一通道，卷积权重是共享的</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lanadeus/article/details/82534425">转置卷积</a></p>
<ul>
<li><p>卷积运算可通过一次矩阵运算实现，因此通过矩阵的转置，实现了 $output -&gt; intput $</p>
<p>正向：$kernel_{4\times16} \times input_{16 \times 1} = output_{4 \times 1}$​​</p>
<p>反向：$ (kernel_{4 \times 16})^T \times output_{4 \times 1} = intput_{16 \times 1}$​</p>
</li>
</ul>
<p><strong>深度可分离卷积</strong></p>
<img src="https://i.loli.net/2021/08/11/wvWyHLOr25XejRG.png" alt="image-20210728170901493.png" style="zoom:67%;" />

<h2 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h2><ul>
<li><blockquote>
<p>通过使用 <code>torch.jit.script</code> 函数来转换模型，我们就有能力编译和优化多层感知机中的计算，而模型的计算结果保持不变。</p>
</blockquote>
</li>
<li><p>池化层</p>
<ol>
<li><em>池化</em>（pooling）层，它具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。</li>
<li>默认情况下，深度学习框架中的步幅与池化窗口的大小相同。</li>
<li>在处理多通道输入数据时，汇聚层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总。 这意味着汇聚层的输出通道数与输入通道数相同。</li>
</ol>
</li>
<li><p>torch.mm 和 torch.mul, torch.matmul的区别</p>
<blockquote>
<ol>
<li><p>torch.mul(a, b)是矩阵a和b对应位相乘，a和b的维度必须相等，比如a的维度是(1, 2)，b的维度是(1, 2)，返回的仍是(1, 2)的矩阵；</p>
</li>
<li><p>torch.mm(a, b)是矩阵a和b矩阵相乘，比如a的维度是(1, 2)，b的维度是(2, 3)，返回的就是(1, 3)的矩阵。<br>PS：更接地气来说区别就是点乘，和矩阵乘法的区别</p>
</li>
<li><p>torch.matmul(input, other, *, out=None) → Tensor</p>
</li>
</ol>
<p>  Matrix product of two tensors.</p>
<p>  The behavior depends on the dimensionality of the tensors as follows:</p>
<p>  <img src="https://i.loli.net/2021/08/11/3CvuUHsFY7LgVjb.png" alt="image-20210811152012438.png"></p>
</blockquote>
</li>
<li><blockquote>
<p>不经意地移动数据可能会显著降低性能。一个典型的错误如下：计算GPU上每个小批量的损失，并在命令行中将其报告给用户（或将其记录在NumPy <code>ndarray</code>中）时，将触发全局解释器锁，从而使所有GPU阻塞。最好是为GPU内部的日志分配内存，并且只移动较大的日志。</p>
</blockquote>
</li>
<li><p>torch.bmm</p>
<p><img src="https://i.loli.net/2021/08/11/JwaKOfFZV73poqj.png" alt="图片.png"></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/xiexu911/article/details/80820028">pytorch学习 中 torch.squeeze() 和torch.unsqueeze()的用法</a></p>
</li>
<li><p>torch.repeat_interleave用法</p>
<blockquote>
<p>torch.repeat_interleave(<em>input</em>, <em>repeats</em>, <em>dim=None</em>) → Tensor</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.repeat_interleave(<span class="number">2</span>)</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.repeat_interleave(y, <span class="number">2</span>)</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.repeat_interleave(y, <span class="number">3</span>, dim=<span class="number">1</span>)</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.repeat_interleave(y, torch.tensor([<span class="number">1</span>, <span class="number">2</span>]), dim=<span class="number">0</span>)</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>]])</span><br></pre></td></tr></table></figure></li>
<li><p>一个模型中出现共享层时，一次backward()是否会导致共享层的最终grad是两个共享层梯度的和（因为一次backward()过程中，共享层第一次计算出的grad没有被清零），从而梯度下降时有更大的步幅，收敛的速度也更快呢？</p>
<blockquote>
<p>理论上是的。你也可以选择关掉（frozen）任何一层的grad。</p>
</blockquote>
</li>
<li><p>参数初始化(使用初始化函数)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.apply(int_function) <span class="comment"># </span></span><br></pre></td></tr></table></figure></li>
<li><p>访问参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].state_dict())</span><br><span class="line"><span class="built_in">print</span>(*[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> net[<span class="number">0</span>].named_parameters()])</span><br><span class="line"><span class="built_in">print</span>(*[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters()])</span><br></pre></td></tr></table></figure></li>
<li><p>在定义网络结构时，使用<code>self._modules</code> 和 <code>list</code>的区别</p>
<blockquote>
<p>The main difference is that using _modules enables the other pytorch  functions/methods to find the added layers automatically. To put it in  another word, these layers will be registered. For example, if you want  to print parameters of the network, you can simply call state_dicts().  But if the list is adopted, methods like state_dicts don’t work.<br> Code:<br> class MySequential(nn.Module):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *args</span>):</span></span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="keyword">for</span> i,block <span class="keyword">in</span> <span class="built_in">enumerate</span>(args):</span><br><span class="line">        self._modules[<span class="built_in">str</span>(i)] = block</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">    <span class="keyword">for</span> block <span class="keyword">in</span> self._modules.values():</span><br><span class="line">        X = block(X)</span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>

<p>net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))<br>net.state_dicts()</p>
</blockquote>
</li>
<li><p><code>torch.clamp</code></p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">      | <span class="built_in">min</span>, <span class="keyword">if</span> x_i &lt; <span class="built_in">min</span></span><br><span class="line">y_i = | x_i, <span class="keyword">if</span> <span class="built_in">min</span> &lt;= x_i &lt;= <span class="built_in">max</span></span><br><span class="line">      | <span class="built_in">max</span>, <span class="keyword">if</span> x_i &gt; <span class="built_in">max</span></span><br></pre></td></tr></table></figure>

<ul>
<li>广播机制</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">3</span>).reshape(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">b = np.arange(<span class="number">2</span>).reshape(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">(array([[<span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>]]),</span><br><span class="line"> array([[<span class="number">0.</span>, <span class="number">1.</span>]]))</span><br><span class="line">a+b</span><br><span class="line">array([[<span class="number">0.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">       [<span class="number">2.</span>, <span class="number">3.</span>]])</span><br></pre></td></tr></table></figure>

<ul>
<li><p>.numpy<code>和</code>.from_numpy<code>方法是可以共享内存的，但如果使用</code>torch.tensor(ndarray)`由numpy数组生成tensor，就不会共享内存。</p>
</li>
<li><p>os.makedirs(name, mode=0o777, exist_ok=False)</p>
<p>用来创建多层目录</p>
<p>exist_ok：是否在目录存在时触发异常。如果exist_ok为<strong>False</strong>（默认值），则在目标目录已存在的情况下<strong>触发</strong>FileExistsError异常；如果exist_ok为<strong>True</strong>，则在目标目录已存在的情况下<strong>不会触发</strong>FileExistsError异常。</p>
</li>
<li><p>os.path.join()函数：连接两个或更多的路径名组件</p>
<ol>
<li>如果各组件名首字母不包含’/‘，则函数会自动加上</li>
<li>如果有一个组件是一个绝对路径，则在它之前的所有组件均会被舍弃</li>
<li>如果最后一个组件为空，则生成的路径以一个’/‘分隔符结尾</li>
</ol>
</li>
<li><p>```<br>A = torch.arange(20, dtype=torch.float32).reshape(5, 4)<br>B = A.clone()  # 通过分配新内存，将A的一个副本分配给B</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- axis指定哪个维度，哪个维度就会消失，`e.g.`  $5 \times 4$​​ 按照axis=0, 会产生4,的结果</span><br><span class="line"></span><br><span class="line">- ![image-20210728201151785.png](https://i.loli.net/2021/08/11/ZQut5csbeJKdxIN.png)</span><br><span class="line"></span><br><span class="line">- ```python</span><br><span class="line">  x = np.arange(0, 3, 0.1)</span><br><span class="line">  plot(x, [f(x), 2 * x - 3], &#x27;x&#x27;, &#x27;f(x)&#x27;, legend=[&#x27;f(x)&#x27;, &#x27;Tangent line (x=1)&#x27;])</span><br></pre></td></tr></table></figure></li>
<li><p>PyTorch梯度累加</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://xingwxiong.github.io/2020/04/07/gradients-accumulation/">PyTorch 梯度累积小技巧</a></li>
<li></li>
</ol>
</li>
<li><p><code>random.shuffle</code> () # in-place操作</p>
</li>
<li><p><code>torch.no_grad()</code> 是一个上下文管理器，被该语句 wrap 起来的部分将不会track 梯度。</p>
</li>
<li><p><code>TensorDataset</code> 可以用来对 tensor 进行打包，就好像 python 中的 zip 功能</p>
</li>
<li><p><code>DataLoader</code> 就是用来包装所使用的数据，每次抛出一批数据</p>
</li>
<li><p>训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.03</span>)</span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        l = loss(net(X), y)</span><br><span class="line">        trainer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        trainer.step()</span><br><span class="line">    l = loss(net(features), labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;l:f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p><code>Why do we need to call zero_grad() in PyTorch?</code></p>
<p><img src="https://i.loli.net/2021/08/11/GetlfbPrKEyhzk1.png" alt="image-20210802103008159.png"></p>
</li>
<li><p><img src="https://i.loli.net/2021/08/11/vXzr2akjJOcWwA7.png" alt="image-20210802112623723.png"></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.yisu.com/zixun/455005.html">Pytorch中net.train 和 net.eval怎么用</a></p>
</li>
<li><p>torch <code>apply</code> <a target="_blank" rel="noopener" href="https://blog.csdn.net/daydayjump/article/details/80899029">参数初始化</a></p>
</li>
<li><p>重新审视Softmax的实现技巧</p>
<p><img src="https://i.loli.net/2021/08/11/6FS4YEvt1IaDLpn.png" alt="image-20210802154905553.png"></p>
</li>
<li><p>Pytorch的backward()相关理解</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/douhaoexia/article/details/78821428">博客1</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/pengge0433/article/details/79459679">Pytorch中的variable, tensor与numpy相互转化的方法</a></p>
</li>
<li><p>顺序块</p>
</li>
<li><p><img src="https://i.loli.net/2021/08/11/EiWR3JegfbTNP2V.png" alt="image-20210805193118474.png"></p>
</li>
<li><p><code>VGG</code>块的实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg_block</span>(<span class="params">num_convs, in_channels, out_channels</span>):</span></span><br><span class="line">    layers = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">        layers.append(nn.Conv2d(in_channels, out_channels,</span><br><span class="line">                                kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">        layers.append(nn.ReLU())</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    layers.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure></li>
<li><p>小批量实现多<code>GPU</code>训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">allreduce</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(data)):</span><br><span class="line">        data[<span class="number">0</span>][:] += data[i].to(data[<span class="number">0</span>].device)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(data)):</span><br><span class="line">        data[i] = data[<span class="number">0</span>].to(data[i].device)</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_batch</span>(<span class="params">X, y, devices</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;将`X`和`y`拆分到多个设备上&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> X.shape[<span class="number">0</span>] == y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> (nn.parallel.scatter(X, devices),</span><br><span class="line">            nn.parallel.scatter(y, devices))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_batch</span>(<span class="params">X, y, device_params, devices, lr</span>):</span></span><br><span class="line">    X_shards, y_shards = split_batch(X, y, devices)</span><br><span class="line">    <span class="comment"># 在每个GPU上分别计算损失</span></span><br><span class="line">    ls = [loss(lenet(X_shard, device_W), y_shard).<span class="built_in">sum</span>()</span><br><span class="line">          <span class="keyword">for</span> X_shard, y_shard, device_W <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">              X_shards, y_shards, device_params)]</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> ls:  <span class="comment"># 反向传播在每个GPU上分别执行</span></span><br><span class="line">        l.backward()</span><br><span class="line">    <span class="comment"># 将每个GPU的所有梯度相加，并将其广播到所有GPU</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(device_params[<span class="number">0</span>])):</span><br><span class="line">            allreduce([device_params[c][i].grad <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(devices))])</span><br><span class="line">    <span class="comment"># 在每个GPU上分别更新模型参数</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> device_params:</span><br><span class="line">        d2l.sgd(param, lr, X.shape[<span class="number">0</span>]) <span class="comment"># 在这里，我们使用全尺寸的小批量</span></span><br></pre></td></tr></table></figure></li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/102697821">Pytorch的nn.DataParallel</a></p>
<p>用多个GPU来加速训练、以及一些疑问</p>
</li>
<li><p><img src="https://i.loli.net/2021/09/08/S7Bi3ZNCKjIdfYW.png" alt="图片.png"></p>
<p><code>nn.CrossEntropyLoss</code></p>
</li>
</ul>
<h2 id="网络的trick"><a href="#网络的trick" class="headerlink" title="网络的trick"></a>网络的trick</h2><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p><a target="_blank" rel="noopener" href="https://easyai.tech/ai-definition/attention/">Attention 机制</a></p>
<h3 id="批量归一化（BN）"><a href="#批量归一化（BN）" class="headerlink" title="批量归一化（BN）"></a>批量归一化（<code>BN</code>）</h3><blockquote>
<p>批量归一化应用于单个可选层（也可以应用到所有层），其原理如下：在每次训练迭代中，我们首先归一化输入，即通过减去其均值并除以其标准差，其中两者均基于当前小批量处理。 接下来，我们应用比例系数和比例偏移。 正是由于这个基于<em>批量</em>统计的<em>标准化</em>，才有了<em>批量归一化</em>的名称。</p>
<p>请注意，在应用批量归一化时，批量大小的选择可能比没有批量归一化时更重要。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。</span></span><br><span class="line"><span class="comment"># 这里我们需要保持X的形状以便后面可以做广播运算</span></span><br><span class="line">mean = X.mean(dim=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdim=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>



<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><blockquote>
<p>此外，你可能会问为什么我们首先使用<code>L2</code>范数，而不是<code>L1</code>范数。事实上，这些选择在整个统计领域中都是有效的和受欢迎的。<code>L2</code>正则化线性模型构成经典的<em>岭回归</em>（ridge regression）算法，<code>L1</code>正则化线性回归是统计学中类似的基本模型，通常被称为<em>套索回归</em>（lasso regression）。</p>
<p>使用<code>L2</code>范数的一个原因是它对权重向量的大分量施加了巨大的惩罚。这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。在实践中，这可能使它们对单个变量中的观测误差更为鲁棒。相比之下，<code>L1</code> 惩罚会导致模型将其他权重清除为零而将权重集中在一小部分特征上。这称为<em>特征选择</em>（feature selection），这可能是其他场景下需要的。</p>
</blockquote>
<h3 id="Drop-out"><a href="#Drop-out" class="headerlink" title="Drop-out"></a>Drop-out</h3><p><img src="https://i.loli.net/2021/08/11/SH2xibAz6g3CoQI.png" alt="image-20210803151851720.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(torch.Tensor(X.shape).uniform_(<span class="number">0</span>, <span class="number">1</span>) &gt; dropout).<span class="built_in">float</span>() <span class="comment"># X 应为Tensor</span></span><br></pre></td></tr></table></figure>

<h2 id="Pytorch求解一般性的优化问题"><a href="#Pytorch求解一般性的优化问题" class="headerlink" title="Pytorch求解一般性的优化问题"></a>Pytorch求解一般性的优化问题</h2><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/363852642">用pytorch梯度下降求解非线性规划问题</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/363852642">用pytorch做简单的最优化问题</a></li>
<li><a target="_blank" rel="noopener" href="https://suool.net/2019/03/01/optimization-problem/">https://suool.net/2019/03/01/optimization-problem/</a></li>
</ul>
<h2 id="环境变量设置"><a href="#环境变量设置" class="headerlink" title="环境变量设置"></a>环境变量设置</h2><p><img src="https://i.loli.net/2021/08/11/Z9wGnbjD7P1aJR3.png" alt="image-20210803093618360.png"></p>
<h2 id="相对误差和绝对误差"><a href="#相对误差和绝对误差" class="headerlink" title="相对误差和绝对误差"></a>相对误差和绝对误差</h2><p><img src="https://i.loli.net/2021/08/11/7pMN2IFuOEbGVX5.png" alt="image-20210804195722558.png"></p>
<p><img src="https://i.loli.net/2021/08/11/Bp9neEPQfTvd8gR.png" alt="image-20210804200013859.png"></p>
<h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><h3 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h3><p>list转为numpy时，要保证三维大小要统一。举例，列表<code>[[1,2,3],[2,3]]</code>转为<code>numpy</code>时会导致格式问题。</p>
<h3 id="Python之彻底清空文件夹"><a href="#Python之彻底清空文件夹" class="headerlink" title="Python之彻底清空文件夹"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/zong596568821xp/article/details/81196954">Python之彻底清空文件夹</a></h3><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43867619/article/details/91838350">Python清除异常值四分位法</a></p>
<h3 id="bool值取反"><a href="#bool值取反" class="headerlink" title="bool值取反"></a>bool值取反</h3><p><a target="_blank" rel="noopener" href="https://www.codenong.com/7030831/">https://www.codenong.com/7030831/</a></p>
<h3 id="python图像支持中文"><a href="#python图像支持中文" class="headerlink" title="python图像支持中文"></a>python图像支持中文</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h3 id="pyplot"><a href="#pyplot" class="headerlink" title="pyplot"></a>pyplot</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.clf() <span class="comment">#清除上一幅图像</span></span><br><span class="line">plt.pause(<span class="number">0.01</span>)  <span class="comment"># 暂停0.01秒</span></span><br><span class="line">plt.ioff()  <span class="comment"># 关闭画图的窗口</span></span><br><span class="line"><span class="comment"># 设置legend</span></span><br><span class="line">line=plt.plot(data)</span><br><span class="line">plt.legend([line],[<span class="string">&#x27;description&#x27;</span>]) <span class="comment"># 若多条曲线以列表格式添加元素</span></span><br><span class="line">plt.scatter(x,y, s=<span class="number">50</span>, c=<span class="string">&#x27;yellow&#x27;</span>) <span class="comment"># 散点图，s控制大小，c控制颜色</span></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_36219858/article/details/79800460">plot参数详解</a></p>
<h3 id="函数的用法"><a href="#函数的用法" class="headerlink" title="函数的用法"></a>函数的用法</h3><ul>
<li><p><strong>slice()</strong> 函数实现切片对象</p>
<p>start –  起始位置，stop –  结束位置，step –  间距</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/walo/p/10608436.html">Python 字符串前面加u,r,b,f的含义</a></p>
</li>
</ul>
<h3 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h3><p><a target="_blank" rel="noopener" href="https://www.liaoxuefeng.com/wiki/897692888725344/923056118147584">资料1</a></p>
<h3 id="特殊用法"><a href="#特殊用法" class="headerlink" title="特殊用法"></a>特殊用法</h3><ul>
<li><p>列表前面加星号作用是将列表解开成两个独立的参数，传入函数，</p>
<p>字典前面加两个星号，是将字典解开成独立的元素作为形参。</p>
</li>
</ul>
<h1 id="跟踪算法"><a href="#跟踪算法" class="headerlink" title="跟踪算法"></a>跟踪算法</h1><h3 id="Sort"><a href="#Sort" class="headerlink" title="Sort"></a>Sort</h3><ul>
<li></li>
</ul>
<h3 id="DeepSort"><a href="#DeepSort" class="headerlink" title="DeepSort"></a>DeepSort</h3><p><strong>track</strong> 的处理</p>
<ol>
<li>Tracks that exceed a predefined maximum age Amax are considered to have left the scene and are deleted from the track set.</li>
<li>New track hypotheses are initiated for each detection that cannot be associated to an existing track. These new tracks are classified as tentative during their first three frames. During this time, we expect a successful measurement association at each time step. Tracks that are not successfully associated to a measurement within their first three frames are deleted.</li>
</ol>
<p><strong>Assignment Probem</strong></p>
<ol>
<li>On the one hand, the Mahalanobis distance provides information about possible object locations based on motion that are particularly useful for short-term predictions.</li>
<li>On the other hand, the cosine distance considers appearance information that are particularly useful to recover identities after longterm occlusions, when motion is less discriminative.</li>
<li><img src="C:\Users\wanji\AppData\Roaming\Typora\typora-user-images\image-20210813152202512.png" alt="image-20210813152202512" style="zoom:67%;" /></li>
</ol>
<h1 id="外参标定软件"><a href="#外参标定软件" class="headerlink" title="外参标定软件"></a>外参标定软件</h1><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><h4 id="cv2-Rodrigues"><a href="#cv2-Rodrigues" class="headerlink" title="cv2.Rodrigues"></a>cv2.Rodrigues</h4><p><img src="https://i.loli.net/2021/08/11/UyOIDmRsexqLorp.png" alt="image-20210805164958695.png"></p>
<h3 id="QtDesigner"><a href="#QtDesigner" class="headerlink" title="QtDesigner"></a>QtDesigner</h3><h3 id="Python之日志处理（logging模块）"><a href="#Python之日志处理（logging模块）" class="headerlink" title="Python之日志处理（logging模块）"></a><a target="_blank" rel="noopener" href="https://www.cnblogs.com/yyds/p/6901864.html">Python之日志处理（logging模块）</a></h3><h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><h2 id="VsCode下的C-配置"><a href="#VsCode下的C-配置" class="headerlink" title="VsCode下的C++配置"></a>VsCode下的C++配置</h2><ol>
<li><p>VsCode下载c/c++扩展</p>
</li>
<li><p>下载MinGW解释器</p>
</li>
<li><p>将MinGW添加到环境变量中</p>
<p>在终端 输入 <code>gcc -v</code>测试是否成功</p>
</li>
<li><img src="https://i.loli.net/2021/08/13/1S3dxEAzyQBwr8c.gif" alt="vscode_c__设置.gif" style="zoom:67%;" /></li>
</ol>
<p><code>launch.json</code>和<code>tasks.json</code>会自动生成，不需要像某些博客讲的手动填入内容</p>
<h1 id="C-学习笔记"><a href="#C-学习笔记" class="headerlink" title="C++学习笔记"></a>C++学习笔记</h1><h2 id="关键字"><a href="#关键字" class="headerlink" title="关键字"></a>关键字</h2><h3 id="auto"><a href="#auto" class="headerlink" title="auto"></a>auto</h3><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/QG-whz/p/4951177.html">C++11特性：auto关键字</a></p>
<h3 id="extern用法"><a href="#extern用法" class="headerlink" title="extern用法"></a><strong>extern用法</strong></h3><blockquote>
<p><strong>extern</strong>是一种“<strong>外部声明</strong>”的关键字，字面意思就是<strong>在此处声明</strong>某种变量或函数，<strong>在外部定义</strong>。</p>
</blockquote>
<h3 id="C-中的-inline-用法"><a href="#C-中的-inline-用法" class="headerlink" title="C++ 中的 inline 用法"></a>C++ 中的 inline 用法</h3><blockquote>
<p>在 c/c++ 中，为了解决一些频繁调用的小函数大量消耗栈空间（栈内存）的问题，特别的引入了 inline 修饰符，表示为内联函数。</p>
<p>栈空间就是指放置程序的局部数据（也就是函数内数据）的内存空间。</p>
<p><a target="_blank" rel="noopener" href="https://www.runoob.com/w3cnote/cpp-inline-usage.html">https://www.runoob.com/w3cnote/cpp-inline-usage.html</a></p>
</blockquote>
<h3 id="this指针"><a href="#this指针" class="headerlink" title="this指针"></a>this指针</h3><blockquote>
<p>在 C++ 中，每一个对象都能通过 <strong>this</strong> 指针来访问自己的地址。<strong>this</strong> 指针是所有成员函数的隐含参数。因此，在成员函数内部，它可以用来指向调用对象。</p>
<p>友元函数没有 <strong>this</strong> 指针，因为友元不是类的成员。只有成员函数才有 <strong>this</strong> 指针。</p>
</blockquote>
<h2 id="注意的点"><a href="#注意的点" class="headerlink" title="注意的点"></a>注意的点</h2><ol>
<li>一个程序局部和全局变量的名称可以相同，但局部变量的值在函数内部将优先采用。</li>
<li>当局变量被定义，它不是由系统初始化，而是用户必须自己初始化。全局变量是由当它们定义为如下系统自动初始化.</li>
<li>引用通常用于函数参数列表和函数返回值。</li>
<li>通过小实例，我们无法区分 cout、cerr 和 clog 的差异，但在编写和执行大型程序时，它们之间的差异就变得非常明显。所以良好的编程实践告诉我们，使用 cerr 流来显示错误消息，而其他的日志消息则使用 clog 流来输出。</li>
<li><img src="https://i.loli.net/2021/08/16/NFazgkWo1i2Bj35.png" alt="图片.png" style="zoom:80%;" /></li>
<li><img src="https://i.loli.net/2021/08/16/ZzecHC14xr7J8WR.png" alt="图片.png" style="zoom:80%;" /></li>
</ol>
<h2 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h2><ol>
<li>C++ 字符串指针和字符串指针数组详解](<a target="_blank" rel="noopener" href="https://www.huaweicloud.com/articles/12586791.html">https://www.huaweicloud.com/articles/12586791.html</a>)</li>
<li><a target="_blank" rel="noopener" href="http://www.baidu.com/link?url=nHwC56N9Dl_iJKoAQ9uIxi2ayT25E0kLbS9p2lB9AaQ0Qm06lz2CIG-7SnBsVPjNOZGqaxZnbnHBweSprU6Dma&wd=&eqid=fcddb67f00049f4d00000003611e1e33">C++中NULL和nullptr的区别 - 苦涩的茶 - 博客园</a></li>
</ol>
<h2 id="零散知识点"><a href="#零散知识点" class="headerlink" title="零散知识点"></a>零散知识点</h2><ol>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/huachizi/article/details/89518453">warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21997625/article/details/84672775">C++map和unordered_map区别和使用</a></p>
<p><a target="_blank" rel="noopener" href="http://c.biancheng.net/view/7231.html">C++ STL unordered_map容器用法详解</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq457163027/article/details/54237782">C++ 点(.)操作符和箭头(-&gt;)操作符</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="http://c.biancheng.net/cpp/biancheng/view/136.html">c++中的模板函数</a></p>
</li>
</ol>
<h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><h3 id="vector"><a href="#vector" class="headerlink" title="vector"></a>vector</h3><p><a target="_blank" rel="noopener" href="https://www.runoob.com/w3cnote/cpp-vector-container-analysis.html">C++ vector 容器浅析</a></p>
<p><img src="C:\Users\wanji\AppData\Roaming\Typora\typora-user-images\image-20210906172718775.png" alt="image-20210906172718775"></p>
<p>示例(杨辉三角的创建)</p>
<p><img src="https://pic.leetcode-cn.com/1626927345-DZmfxB-PascalTriangleAnimated2.gif" alt="杨辉三角"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="class"><span class="title">public</span>:</span></span><br><span class="line">    vector&lt;vector&lt;<span class="built_in">int</span>&gt;&gt; generate(<span class="built_in">int</span> numRows) &#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="built_in">int</span>&gt;&gt; ret(numRows);</span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; numRows; ++i) &#123;</span><br><span class="line">            ret[i].resize(i + <span class="number">1</span>);</span><br><span class="line">            ret[i][<span class="number">0</span>] = ret[i][i] = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="built_in">int</span> j = <span class="number">1</span>; j &lt; i; ++j) &#123;</span><br><span class="line">                ret[i][j] = ret[i - <span class="number">1</span>][j] + ret[i - <span class="number">1</span>][j - <span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="stack"><a href="#stack" class="headerlink" title="stack"></a><a target="_blank" rel="noopener" href="http://c.biancheng.net/view/6971.html">stack</a></h3><h3 id="stack-及-map-的用法示例"><a href="#stack-及-map-的用法示例" class="headerlink" title="stack 及 map 的用法示例"></a>stack 及 map 的用法示例</h3><p><strong>判断有效的括号字符串</strong>00` </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unordered_map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isValid</span><span class="params">(string s)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n=s.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span> (n%<span class="number">2</span>==<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 字典和栈的定义</span></span><br><span class="line">        unordered_map&lt;<span class="keyword">char</span>,<span class="keyword">char</span>&gt; pairs=&#123;</span><br><span class="line">            &#123;<span class="string">&#x27;)&#x27;</span>, <span class="string">&#x27;(&#x27;</span>&#125;,</span><br><span class="line">            &#123;<span class="string">&#x27;]&#x27;</span>, <span class="string">&#x27;[&#x27;</span>&#125;,</span><br><span class="line">            &#123;<span class="string">&#x27;&#125;&#x27;</span>, <span class="string">&#x27;&#123;&#x27;</span>&#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        stack&lt;<span class="keyword">char</span>&gt; stk;</span><br><span class="line">        <span class="comment">// 循环方式</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">char</span> ch:s)&#123;</span><br><span class="line">            <span class="comment">// 判断 键&quot;ch&quot;是否在 map中</span></span><br><span class="line">            <span class="keyword">if</span> (pairs.<span class="built_in">count</span>(ch))&#123;</span><br><span class="line">                <span class="comment">// 判断栈是否为空以及判断栈顶元素是否等于键&quot;ch&quot;的值</span></span><br><span class="line">                <span class="keyword">if</span> (stk.<span class="built_in">empty</span>() || stk.<span class="built_in">top</span>()!=pairs[ch])</span><br><span class="line">                &#123;<span class="keyword">return</span> <span class="literal">false</span>;&#125;</span><br><span class="line">                stk.<span class="built_in">pop</span>(); <span class="comment">// 弹出元素</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                stk.<span class="built_in">push</span>(ch);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> stk.<span class="built_in">empty</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><h3 id="unordered-map"><a href="#unordered-map" class="headerlink" title="unordered_map"></a>unordered_map</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> x:unomap)<span class="comment">//遍历整个map，输出key及其对应的value值</span></span><br><span class="line">&#123;</span><br><span class="line">	x.second = <span class="number">0</span>;	</span><br><span class="line">	cout&lt;&lt;x.second&lt;&lt;endl;<span class="comment">//全是  000；;	</span></span><br><span class="line">&#125;</span><br><span class="line">cout&lt;&lt;x.second&lt;&lt;endl;<span class="comment">//回复原来的数值的。</span></span><br><span class="line"><span class="comment">//彻底改变：使用find彻底找到这个数值，然后在进行改，可以保证作用域是整个程序。</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> x:unomap)<span class="comment">//遍历整个map，输出key及其对应的value值</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">auto</span> it = umap.<span class="built_in">find</span>(key) <span class="comment">//改</span></span><br><span class="line">	<span class="keyword">if</span>(it != umap.<span class="built_in">end</span>()) </span><br><span class="line">	    it-&gt;second = new_value; </span><br><span class="line">&#125;	</span><br></pre></td></tr></table></figure>

<p><strong>注意：使用auto循环时候，修改的值作用域仅仅循环之内，出去循环还会变成未修改的数值。</strong></p>
<h3 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h3><p><img src="https://i.loli.net/2021/08/17/WKSz68CqZJtXpLh.png" alt="图片.png"></p>
<h3 id="友元函数"><a href="#友元函数" class="headerlink" title="友元函数"></a>友元函数</h3><p>类的友元函数是定义在类外部，但有权访问类的所有私有（private）成员和保护（protected）成员。尽管友元函数的原型有在类的定义中出现过，但是友元函数并不是成员函数。</p>
<p>友元可以是一个函数，该函数被称为友元函数；友元也可以是一个类，该类被称为友元类，在这种情况下，整个类及其所有成员都是友元。</p>
<p>如果要声明函数为一个类的友元，需要在类定义中该函数原型前使用关键字 <strong>friend</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">   <span class="keyword">double</span> width;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">   <span class="keyword">double</span> length;</span><br><span class="line">   <span class="function"><span class="keyword">friend</span> <span class="keyword">void</span> <span class="title">printWidth</span><span class="params">( Box box )</span></span>;</span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">setWidth</span><span class="params">( <span class="keyword">double</span> wid )</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>




      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/07/28/%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%AE%B0/" data-id="ckto3u194000620ia0ex75f6a" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2017年来相关的3D视觉点云算法论文阅读笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/07/15/2017%E5%B9%B4%E6%9D%A5%E7%9B%B8%E5%85%B3%E7%9A%843D%E8%A7%86%E8%A7%89%E7%82%B9%E4%BA%91%E7%AE%97%E6%B3%95%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2021-07-15T12:34:09.693Z" itemprop="datePublished">2021-07-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="PointNet-系列论文阅读笔记"><a href="#PointNet-系列论文阅读笔记" class="headerlink" title="PointNet 系列论文阅读笔记"></a>PointNet 系列论文阅读笔记</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/336496973">论文解读博客 - <strong>推荐</strong></a></p>
<h2 id="PointNet-Deep-Learning-on-Point-Sets-for-3D-Classification-and-Segmentation"><a href="#PointNet-Deep-Learning-on-Point-Sets-for-3D-Classification-and-Segmentation" class="headerlink" title="PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"></a>PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</h2><h3 id="4-2-PointNet-Architecture"><a href="#4-2-PointNet-Architecture" class="headerlink" title="4.2 PointNet Architecture"></a>4.2 PointNet Architecture</h3><p>该部分中包含对高维point排序的讨论，</p>
<blockquote>
<p>does not exist an ordering that is stable w.r.t. point perturbations in the general<br>sense. </p>
</blockquote>
<p>并给出了通俗的解释。</p>
<p>利用网络的搭建来逼近一个所需的对称函数</p>
<blockquote>
<p><img src="https://i.loli.net/2021/08/11/7f52dRksvcOtjKh.png" alt="image-20210720094537797.png"></p>
</blockquote>
<blockquote>
<p>为了保证输入点云的<strong>不变性</strong>，作者在进行特征提取前先对点云数据进行<strong>对齐操作</strong>（也就是input transform），对齐操作是通过训练一个小型的网络（也就是上图中的T-Net）来得到<strong>转换矩阵</strong>，并将之和输入点云数据相乘来实现。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">max</span>(<span class="built_in">input</span>, dim, keepdim=<span class="literal">False</span>, out=<span class="literal">None</span>) -&gt; (Tensor, LongTensor)</span><br><span class="line"><span class="comment"># 按维度dim 返回最大值：0代表列，1代表行</span></span><br><span class="line"><span class="comment"># If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of size 1.</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">1</span>, <span class="number">17</span>)  <span class="comment"># a&#x27;s shape is (16,)</span></span><br><span class="line">a.view(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>) <span class="comment"># output below</span></span><br><span class="line">tensor([[[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>],</span><br><span class="line">         [ <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>]],</span><br><span class="line"> </span><br><span class="line">        [[ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>]]])</span><br><span class="line">[torch.FloatTensor of size 2x2x4]</span><br></pre></td></tr></table></figure>

<p><strong>先按列排，再按行排，最后按页排</strong></p>
<p><code>.repeat</code>用法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.repeat(<span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.repeat(<span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>).size()</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/156825903">Conv1D和Conv2D的区别</a></p>
<blockquote>
<p>一言概括，2d先横着扫再竖着扫，1d只能竖着扫</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://renzibei.com/2020/06/30/conv1d%E4%B8%8Econv2d%E7%9A%84%E5%8C%BA%E5%88%AB/">https://renzibei.com/2020/06/30/conv1d%E4%B8%8Econv2d%E7%9A%84%E5%8C%BA%E5%88%AB/</a></p>
<p><img src="https://i.loli.net/2021/08/11/g2BPXMWZlHKNu4R.png" alt="image-20210722193611214.png"></p>
<h2 id="PointNet-Deep-Hierarchical-Feature-Learning-on-Point-Sets-in-a-Metric-Space"><a href="#PointNet-Deep-Hierarchical-Feature-Learning-on-Point-Sets-in-a-Metric-Space" class="headerlink" title="PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"></a>PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</h2><blockquote>
<p>We introduce a hierarchical neural network, named as PointNet++, to process a set of points sampled<br>in a metric space in a hierarchical fashion.</p>
<p>Similar to CNNs, we extract local features capturing fine geometric structures from small<br>neighborhoods; such local features are further grouped into larger units and processed to produce<br>higher level features. This process is repeated until we obtain the features of the whole point set.</p>
<p>We choose our local feature learner to be PointNet.</p>
</blockquote>
<h3 id="Hierarchical-Point-Set-Feature-Learning"><a href="#Hierarchical-Point-Set-Feature-Learning" class="headerlink" title="Hierarchical Point Set Feature Learning"></a>Hierarchical Point Set Feature Learning</h3><blockquote>
<p>Our hierarchical structure is composed by a number of set abstraction levels (Fig. 2). At each level, a<br>set of points is processed and abstracted to produce a new set with fewer elements. The set abstraction<br>level is made of three key layers: Sampling layer, Grouping layer and PointNet layer. The Sampling<br>layer selects a set of points from input points, which defines the centroids of local regions. Grouping<br>layer then constructs local region sets by finding “neighboring” points around the centroids. PointNet<br>layer uses a mini-PointNet to encode local region patterns into feature vectors.</p>
</blockquote>
<ul>
<li><p>Sampling layer</p>
</li>
<li><p>Grouping layer</p>
</li>
</ul>
<p>PointNet++ </p>
<blockquote>
<p>To achieve this goalwe propose density adaptive PointNet layers (Fig. 3) that learn to<br>combine features from regions of different scales when the input sampling density changes. We call<br>our hierarchical network with density adaptive PointNet layers as PointNet++.</p>
<p>PointNet++：a powerful neural network architecture for processing point<br>sets sampled in a metric space. PointNet++ recursively functions on a nested partitioning of the<br>input point set, and is effective in learning hierarchical features with respect to the distance metric.<br>To handle the non uniform point sampling issue, we propose two novel set abstraction layers that<br>intelligently aggregate multi-scale information according to local point densities.</p>
</blockquote>
<h1 id="VoxelNet-论文和代码解析"><a href="#VoxelNet-论文和代码解析" class="headerlink" title="VoxelNet 论文和代码解析"></a>VoxelNet 论文和代码解析</h1><p><strong>可以把上面的PointNet或者PointNet++理解为用于图像分类任务中的ResNet等CNN网络</strong></p>
<blockquote>
<p><strong>CNN模型：ResNet</strong></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/54289848">ResNet及其变种的结构梳理、有效性分析与代码解读</a></p>
<p>网络深度增加时，网络准确度出现饱和，甚至出现下降。</p>
<ul>
<li><p>56层的网络比20层网络效果还要差。这不会是过拟合问题，因为56层网络的训练误差同样高。我们知道深层网络存在着梯度消失或者爆炸的问题，这使得深度学习模型很难训练。但是现在已经存在一些技术手段如BatchNorm来缓解这个问题。</p>
</li>
<li><p><img src="https://i.loli.net/2021/08/11/TSoHfspRD6wZAVL.png" alt="image-20210723100429081.png"></p>
<p>简单地说，原先的网络输入x，希望输出H(x)。现在我们改一改，我们令H(x)=F(x)+x，那么我们的网络就只需要学习输出一个残差F(x)=H(x)-x。作者提出，学习残差F(x)=H(x)-x会比直接学习原始特征H(x)简单的多。</p>
</li>
<li><p><img src="https://i.loli.net/2021/08/11/NUDpHzaWfiCGsqe.png" alt="image-20210723095821692.png"></p>
</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/08/11/aqP9Q86iHIrmToE.png" alt="image-20210723145241437.png"></p>
<blockquote>
<p>既然这样那为什么第一部分依旧要放一个7x7的大卷积核呢，不知道是出于怎样的考虑，但是现在的多数网络都把这部分改成3个3x3卷积核级联。</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/07/15/2017%E5%B9%B4%E6%9D%A5%E7%9B%B8%E5%85%B3%E7%9A%843D%E8%A7%86%E8%A7%89%E7%82%B9%E4%BA%91%E7%AE%97%E6%B3%95%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" data-id="ckto3u18r000020iagz5khhfr" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-内外参标定" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/06/16/%E5%86%85%E5%A4%96%E5%8F%82%E6%A0%87%E5%AE%9A/" class="article-date">
  <time class="dt-published" datetime="2021-06-16T09:47:00.380Z" itemprop="datePublished">2021-06-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="内外参标定"><a href="#内外参标定" class="headerlink" title="内外参标定"></a>内外参标定</h1><ol>
<li><a target="_blank" rel="noopener" href="https://www.mathworks.com/help/vision/ug/fisheye-calibration-basics.html">Fish eye Camera Model</a></li>
</ol>
<blockquote>
<p> In order to relate a 3-D world point on to a 2-D image, you must obtain the camera extrinsic and intrinsic parameters. World points are transformed to camera coordinates using the extrinsic parameters. The camera coordinates are mapped into the image plane using the intrinsics parameters.</p>
</blockquote>
<ol start="2">
<li><p><a target="_blank" rel="noopener" href="https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html">相机标定相关参数</a></p>
<blockquote>
<p>The distortion coefficients do not depend on the scene viewed. Thus, they also belong to the intrinsic camera parameters.</p>
</blockquote>
<p><img src="https://docs.opencv.org/2.4/_images/math/331ebcd980b851f25de1979ebb67a2fed1c8477e.png" alt="\begin{array}{l} \vecthree{x}{y}{z} = R  \vecthree{X}{Y}{Z} + t \\ x&#39; = x/z \\ y&#39; = y/z \\ x&#39;&#39; = x&#39;  \frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6} + 2 p_1 x&#39; y&#39; + p_2(r^2 + 2 x&#39;^2)  \\ y&#39;&#39; = y&#39;  \frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6} + p_1 (r^2 + 2 y&#39;^2) + 2 p_2 x&#39; y&#39;  \\ \text{where} \quad r^2 = x&#39;^2 + y&#39;^2  \\ u = f_x*x&#39;&#39; + c_x \\ v = f_y*y&#39;&#39; + c_y \end{array}"></p>
<blockquote>
<p>for example, a camera has been calibrated on images of <code>320 x 240</code> resolution, absolutely the same distortion coefficients can be used for <code>640 x 480</code> images from the same camera while <img src="https://docs.opencv.org/2.4/_images/math/90cbff5be10b7d5d6a3ec6cabfe05e306e99ac1c.png" alt="f_x">, <img src="https://docs.opencv.org/2.4/_images/math/0a9dfcd96704b05afe921dcabeefcd77bfdbd863.png" alt="f_y">, <img src="https://docs.opencv.org/2.4/_images/math/9b3b5249a3d76623dfc49952e7b1d24fe8c7942f.png" alt="c_x">, and <img src="https://docs.opencv.org/2.4/_images/math/690b7a0c20d6a00f67e5c16ca5dcab66d7969184.png" alt="c_y"> need to be scaled appropriately.</p>
</blockquote>
<p>旋转向量，旋转矩阵</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/mightbxg/article/details/79363699">三维坐标变换——旋转矩阵与旋转向量</a></p>
<p>设旋转向量的单位向量为 <em>r</em>，模为  <em>θ</em>。三维点（或者说三维向量） <em>p</em> 在旋转向量 <em>r</em> 的作用下变换至  <em>p</em>′，则：<br>$$<br>p’=\cos\theta\cdot p+(1-\cos\theta)(p\cdot r)r+\sin\theta\cdot r \times p<br>$$<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/141597984">深入理解旋转矩阵和平移向量的本质</a></p>
<p>[视觉SLAM十四讲（一）之旋转矩阵与旋转向量<a target="_blank" rel="noopener" href="https://www.cnblogs.com/liuhuacai/p/12093770.html">罗德里格斯公式]</a></p>
<p><code>sklearn</code>中的梯度下降，损失函数是固定的。</p>
<p><code>projectpoints</code> 中 disCoeffs:</p>
<blockquote>
<p>Input vector of distortion coefficients (<em>k</em>1,<em>k</em>2,<em>p</em>1,<em>p</em>2[,<em>k</em>3[,<em>k</em>4,<em>k</em>5,<em>k</em>6[,<em>s</em>1,<em>s</em>2,<em>s</em>3,<em>s</em>4[,<em>τ**x</em>,<em>τ**y</em>]]]]) of 4, 5, 8, 12 or 14 elements . If the vector is empty, the zero distortion coefficients are assumed. </p>
</blockquote>
<p>sympy: <code>lambdify</code></p>
</li>
</ol>
<h1 id="冰哥内外参工作"><a href="#冰哥内外参工作" class="headerlink" title="冰哥内外参工作"></a>冰哥内外参工作</h1><h2 id="cmake-visual-studio"><a href="#cmake-visual-studio" class="headerlink" title="cmake, visual studio"></a>cmake, visual studio</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/429861017">https://www.zhihu.com/question/429861017</a></li>
</ol>
<p>(numpy逻辑索引用法)[<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38150441/article/details/79882546]">https://blog.csdn.net/qq_38150441/article/details/79882546]</a></p>
<ul>
<li>np.logical_and</li>
<li>np.logical_or</li>
<li>np.logical_not</li>
</ul>
<p>(np.where用法)[<a target="_blank" rel="noopener" href="https://www.cnblogs.com/massquantity/p/8908859.html]">https://www.cnblogs.com/massquantity/p/8908859.html]</a></p>
<ul>
<li><h3 id="np-where-condition-x-y"><a href="#np-where-condition-x-y" class="headerlink" title="np.where(condition, x, y)"></a>np.where(condition, x, y)</h3><p>满足条件(condition)，输出x，不满足输出y。</p>
</li>
<li><h3 id="np-where-condition"><a href="#np-where-condition" class="headerlink" title="np.where(condition)"></a>np.where(condition)</h3><p>只有条件 (condition)，没有x和y，则输出满足条件元素的坐标 </p>
</li>
</ul>
<h2 id="scipy-optimize-linear-sum-assignment"><a href="#scipy-optimize-linear-sum-assignment" class="headerlink" title="scipy.optimize.linear_sum_assignment"></a>scipy.optimize.linear_sum_assignment</h2><ul>
<li><p><code>scipy.optimize.``linear_sum_assignment</code>(<em>cost_matrix</em>, <em>maximize=False</em>)[<a target="_blank" rel="noopener" href="https://github.com/scipy/scipy/blob/v1.7.0/scipy/optimize/_lsap.py#L16-L100">source]</a></p>
<p>Solve the linear sum assignment problem.</p>
<p>Parameters <strong>cost_matrix</strong>arrayThe cost matrix of the bipartite graph. <strong>maximize</strong>bool (default: False)Calculates a maximum weight matching if true.  </p>
<p>Returns <strong>row_ind, col_ind</strong>arrayAn array of row indices and one of corresponding column indices giving the optimal assignment. The cost of the assignment can be computed as <code>cost_matrix[row_ind, col_ind].sum()</code>. The row indices will be sorted; in the case of a square cost matrix they will be equal to <code>numpy.arange(cost_matrix.shape[0])</code>.</p>
</li>
</ul>
<h1 id="Slam14讲学习笔记"><a href="#Slam14讲学习笔记" class="headerlink" title="Slam14讲学习笔记"></a>Slam14讲学习笔记</h1><p>反对称矩阵</p>
<p><img src="https://i.loli.net/2021/08/11/4Euc5n3MvDLkbmH.png" alt="image-20210701152640157.png"></p>
<p><img src="https://i.loli.net/2021/08/11/mV6fSHqJUyQG5Y9.png" alt="image-20210701153332825.png"></p>
<p>欧拉角，万向锁</p>
<p>欧拉角坐标轴旋转是按顺序旋转的，<strong>父子关系</strong>。</p>
<p><a target="_blank" rel="noopener" href="http://v.youku.com/v_show/id_XNzkyOTIyMTI=.html">讲解视频</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/06/16/%E5%86%85%E5%A4%96%E5%8F%82%E6%A0%87%E5%AE%9A/" data-id="ckto3u194000520iadzzhhxea" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-隧道数据分析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/06/07/%E9%9A%A7%E9%81%93%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2021-06-07T02:01:34.589Z" itemprop="datePublished">2021-06-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="隧道数据分析"><a href="#隧道数据分析" class="headerlink" title="隧道数据分析"></a>隧道数据分析</h1><h2 id="多目标指标分析"><a href="#多目标指标分析" class="headerlink" title="多目标指标分析"></a>多目标指标分析</h2><p><strong>2021.06.07 娟姐给的建议</strong></p>
<blockquote>
<p>统计时可以再多考虑以下维度：</p>
<ul>
<li><p>车辆间距会受到哪些因素的影响，例如速度，可以作为一个统计维度</p>
</li>
<li><p>目标运动的角加速度可以作为一个分析的因素，车辆目标是一个有长度的刚体，行为发生变化时，角加速度不能无限制的大。</p>
</li>
<li><p>变道统计时可以考虑变道目标车道的前后车距，因为变道需要目标车道给予充分的条件</p>
</li>
<li><p>超速、慢行等行为也可以做一些统计</p>
</li>
</ul>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/06/07/%E9%9A%A7%E9%81%93%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" data-id="ckto3u196000920iadjqf3xh0" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-20210508_入职以来工作总结" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/05/08/20210508_%E5%85%A5%E8%81%8C%E4%BB%A5%E6%9D%A5%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="dt-published" datetime="2021-05-08T10:50:49.747Z" itemprop="datePublished">2021-05-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>入职一个月的工作记录</p>
<h2 id="第一周"><a href="#第一周" class="headerlink" title="第一周"></a>第一周</h2><ol>
<li><p>完成了车辆目标框和车辆轨迹线的可视化</p>
<ul>
<li>了解点云数据和8号门的数据协议，使用<code>open3d</code>绘制目标框和轨迹。</li>
</ul>
</li>
<li><p>异常现象的分析和归纳</p>
<ul>
<li><p>观察8号门数据可视化后的结果和智慧平台上的结果，记录出现的异常现象。总结归类。结果如下</p>
<blockquote>
<p>1）车辆异常晃动，多发生在静止的车辆或正在减速停止的车辆，检测跟踪算法对于静止的车辆中心点的检测存在误差，因此导致车辆的晃动（航向角变化，中心点变化）</p>
<p>2）车辆目标框闪烁问题，这是由于检测跟踪的中断导致的。</p>
<p>3）车辆异常的轨迹路线，行进路线不符合正常的运动学模型。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<h2 id="第二周"><a href="#第二周" class="headerlink" title="第二周"></a>第二周</h2><h3 id="对几类异常问题的解决方法"><a href="#对几类异常问题的解决方法" class="headerlink" title="对几类异常问题的解决方法"></a>对几类异常问题的解决方法</h3><ol>
<li><p>解决了车辆目标框异常晃动问题</p>
<p>==20210526 写中期汇报时意识到了一个问题，因为异常晃动，会导致这一两帧的速度也会急剧增大==</p>
<p>当物体为实际静止的情况时，因为检测精度的限制，检测结果中该物体仍然会存在微小的移动。因此我们需要做固定化处理，即固定中心点、航向角。判断物体静止的条件是检测出的物体速度小于 给定的阈值。之后从最新的帧往回退，直到某一帧的box速度大于阈值，停止。将box的位置，航向角固定为该帧中box对应的位置，航向角。</p>
<p><img src="https://i.loli.net/2021/08/11/Zap8qtV5JQckSXO.png" alt="image-20210508192941489.png"></p>
</li>
<li><p>对设计的根据运动的连续性来修正检测结果的方法进行了编程实现。</p>
<p>当假设数据中当前帧的速度和航向角等特征值<strong>不太</strong>准确的情况下，可以从物体状态变换的连续性角度出发，满足一阶连续<br>$$<br>\hat{C_3} \approx C_2 + (C_2-C_1)<br>$$<br>其中 $C_i$ 表示第 $i$ 帧的box位置向量将$\hat{C_3},与检测的C_3综合$，<br>$$<br>\check{C_3}=\alpha \hat{C_3} + (1-\alpha)C_3, \quad \alpha \in [0,1]<br>$$</p>
</li>
<li><p>对于车辆目标框大小变动的问题</p>
<p>在一个目标首次出现时，它的长宽高就要固定下来，在之后每一帧中，长宽高要保持不变。</p>
</li>
</ol>
<h3 id="对目标框闪烁问题的思考和初步的解决方案"><a href="#对目标框闪烁问题的思考和初步的解决方案" class="headerlink" title="对目标框闪烁问题的思考和初步的解决方案"></a>对目标框闪烁问题的思考和初步的解决方案</h3><ul>
<li>目标框的闪烁问题是由于检测和跟踪的中断，导致目标在一帧或连续几帧中消失。因此尝试对缺失的数据进行填补</li>
<li>学习了kalman滤波预测原理，编程实现了利用 kalman滤波对缺失的box数据进行预测填补，测试了算法效果。</li>
</ul>
<p>编程思路：</p>
<blockquote>
<p>针对box目标框闪烁问题<br>维护一个队列，队列中存储的是在上一帧中出现的box_id。<br>for box in queue:<br>    if box not in frame:<br>        该box消失，通过kalman预测填补上该box缺失的信息</p>
</blockquote>
<p>**Note: ** 目前设置的是只对缺失的box连续补6帧，如果6帧后box还未在frame中出现，不再对box进行预测填补。<br>因为物体可能存在ID跳变问题，即同一物体检测的中断前后id不同，预测box和实际box发生<code>重叠</code>。</p>
<p>针对<code>重叠</code>问题的解决：</p>
<blockquote>
<p>在某一帧中：检测到预测的box(id_1)和该帧中的一个box(id_2)发生重叠（计算IOU），将两个box合并，box(id_1)的历史数据给box(id_2),之后只维护box(id_2)。</p>
</blockquote>
<p><img src="https://i.loli.net/2021/08/11/T4zUxvOsIf7n6HD.png" alt="image-20210508194612424.png"></p>
<h2 id="第三周"><a href="#第三周" class="headerlink" title="第三周"></a>第三周</h2><ol>
<li><p>调研了目前车辆轨迹预测的研究工作，尝试用来解决轨迹异常问题。</p>
<ul>
<li>调研当前多目标交互的轨迹预测的工作，查看是否有的方法</li>
<li>学习了Quintic polynomials planning，尝试利用其中的思想来构造异常轨迹的评价方法</li>
<li>查看了轨迹聚类的方法，尝试利用聚类方法来得到置信度最高的轨迹 </li>
</ul>
</li>
<li><p>实现了异常轨迹的判定、尝试复现论文”Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter”</p>
<p>==异常轨迹的判定是检查位移向量的角度变化是否大于设定的阈值。==</p>
<p>编程实现了异常轨迹的判定及修正方法，观察了实验效果 。</p>
<p>修正前后的结果</p>
<ul>
<li><p>修正前</p>
<p><a href="C:\Users\wanji\Videos\Captures\异常轨迹修正前.mp4">结果</a></p>
<p>修正后</p>
<p><a href="C:\Users\wanji\Videos\Captures\异常轨迹修正后.mp4">结果</a></p>
</li>
</ul>
<p>详细阅读了论文”Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter”。</p>
</li>
</ol>
<h2 id="第四周"><a href="#第四周" class="headerlink" title="第四周"></a>第四周</h2><ol>
<li>深入阅读论文”Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter“<ul>
<li>学习了马尔可夫链蒙特卡罗方法的原理。</li>
<li>学习了贝叶斯滤波、粒子滤波。</li>
<li>阅读论文”Maintaining multimodality through mixture tracking“，学习了 mixture particle filter 理论。</li>
</ul>
</li>
<li>查阅了IDM模型（车辆跟随模型）以及一种利用回归方法来做轨迹预测的模型（考虑了周围的车辆信息）。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/05/08/20210508_%E5%85%A5%E8%81%8C%E4%BB%A5%E6%9D%A5%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/" data-id="ckto3u190000120ia3bwabmyo" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-复现论文的学习之路" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/05/06/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" class="article-date">
  <time class="dt-published" datetime="2021-05-06T11:40:53.227Z" itemprop="datePublished">2021-05-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>论文复现的学习之路</p>
<h1 id="论文-Generic-Vehicle-Tracking-Framework-Capable-of-Handling-Occlusions-Based-on-Modified-Mixture-Particle-Filter-papers-车辆路径修正-Generic-Vehicle-Tracking-Framework-Capable-of-Handling-Occlusions-pdf"><a href="#论文-Generic-Vehicle-Tracking-Framework-Capable-of-Handling-Occlusions-Based-on-Modified-Mixture-Particle-Filter-papers-车辆路径修正-Generic-Vehicle-Tracking-Framework-Capable-of-Handling-Occlusions-pdf" class="headerlink" title="论文 [Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter](..\papers\车辆路径修正\Generic Vehicle Tracking Framework Capable of Handling Occlusions.pdf)"></a>论文 [Generic Vehicle Tracking Framework Capable of Handling Occlusions Based on Modified Mixture Particle Filter](..\papers\车辆路径修正\Generic Vehicle Tracking Framework Capable of Handling Occlusions.pdf)</h1><p>$$<br>predict: \quad \int D(x_t|x_{t-1})p(dx_{t-1}|y^{t-1}) \<br>update: \quad \frac{L(y_t|x_t)p(x_t|y^{t-1})}{\int L(y_t|s_t)p(ds_t|y^{t-1})}<br>$$</p>
<h2 id="对论文的理解"><a href="#对论文的理解" class="headerlink" title="对论文的理解"></a>对论文的理解</h2><ul>
<li><p><input disabled="" type="checkbox">  recursive Bayesian state estimation and mixture model representation, 论文 [Maintaining multimodality through mixture tracking](..\papers\车辆路径修正\Maintaining multimodality through mixture tracking.pdf)</p>
<p>$\pi_{m,k}$ is mixture wieght for the m-th component at time step $t$ and $\sum_{m=1}^M \pi_{m,t}=1$</p>
<p>The particle<br>representation implies a Monte Carlo approximation of the mixture filtering distribution of the form<br>$$<br>p(x_t|y^t)=\sum_{m=1}^M \pi_{m,t}\sum_{i \in I_m} w_t^{(i)}\delta_{x_t^{(t)}}(x_t)<br>$$</p>
<blockquote>
<p>The particle filter is a Monte Carlo method that represents the target distribution with a weighted set of samples that are propagated in such a manner so as to maintain a properly weighted sample from the target distribution at subsequent time steps.</p>
</blockquote>
<p>$c_t^{(i)}=m$ if particle $i$ belongs to mixture component $m$. </p>
</li>
</ul>
<p>Bayesian state estimation and mixtu  re model representation</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/varyshare/article/details/97642209">易懂教程我是如何十分钟理解与推导贝叶斯滤波(Bayes Filter)算法？</a></p>
</blockquote>
<p>Bayes公式</p>
<p><img src="https://www.guyuehome.com/Uploads/wp/2020/06/48.png" alt="https://www.guyuehome.com/Uploads/wp/2020/06/48.png"></p>
<p>延伸出的公式</p>
<p><img src="https://www.guyuehome.com/Uploads/wp/2020/06/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20200603145143-300x236.png" alt="https://www.guyuehome.com/Uploads/wp/2020/06/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20200603145143-300x236.png"></p>
<p>理解了上面两张图片中的公式就理解了论文中的 <strong>Prior Update</strong>, <strong>Measurement Update</strong>.</p>
<h3 id="Gaussian-mixture-model-as-the-prediction-model"><a href="#Gaussian-mixture-model-as-the-prediction-model" class="headerlink" title="Gaussian mixture model as the prediction model"></a>Gaussian mixture model as the prediction model</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Kuo_Jun_Lin/article/details/115415884">高斯混合模型还能这样预测新冠发病人数与位置</a></p>
<p>该论文引用的论文： [A probabilistic long term prediction approach for highway scenarios](..\papers\车辆路径修正\A probabilistic long term prediction approach for highway scenarios.pdf) </p>
<p>论文 高斯混合模型做轨迹预测： [Probabilistic trajectory prediction with gaussian mixture models](..\papers\车辆路径修正\Probabilistic trajectory prediction with gaussian mixture models.pdf) </p>
<p><a target="_blank" rel="noopener" href="https://github.com/AlexanderFabisch/gmr/blob/master/examples/plot_trajectories.py">GMR 轨迹回归</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/ceteke/GMM-GMR">This repository contains the implementation of GMM-GMR based imitation learning from multiple trajectories.</a></p>
<h2 id="论文中涉及到的知识点"><a href="#论文中涉及到的知识点" class="headerlink" title="论文中涉及到的知识点"></a>论文中涉及到的知识点</h2><h3 id="粒子滤波算法及原理"><a href="#粒子滤波算法及原理" class="headerlink" title="粒子滤波算法及原理"></a>粒子滤波算法及原理</h3><ul>
<li>The idea of the particle filter (PF: Particle Filter) is based on <em>Monte Carlo methods</em>, which use particle sets to represent probabilities and can be used in any form of state space model. </li>
<li> The core idea is to express its distribution by extracting random state particles from the posterior probability. It is a sequential importance sampling method (Sequential Importance Sampling).</li>
<li><img src="https://miro.medium.com/max/1047/1*uRpfceAICGl10qRz2VvaBg.png" alt="img" style="zoom: 50%;" /></li>
<li>Although the probability distribution in the algorithm is only an  approximation of the real distribution, due to the non-parametric  characteristics, it can get rid of the constraint that the random  quantity must satisfy the Gaussian distribution when solving the  nonlinear filtering problem, and can express a wider distribution than  the Gaussian model.</li>
</ul>
<blockquote>
<p>Particle filters methods are recursive Bayesian filters which provide a  convenient and attractive approach to approximate the posterior  distributions when the model is nonlinear and when the noises are not  Gaussian.</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/pSCE3hn6jsqq11NC0rK5mw">什么是粒子滤波</a></p>
<blockquote>
<ul>
<li>重要性采样（IS）</li>
<li>序列重要性采样和重采样（SIS）</li>
</ul>
<p>粒子滤波就是<strong>“序列重要性采样+重采样”</strong>的结果</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/piaoxuezhong/article/details/78619150">从原理到实现讲解粒子滤波</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/rhymesg/Particle_Filter"><code>mixture particle filter</code> github 实现</a></p>
<p>通俗理解SLAM算法</p>
<blockquote>
<p>SLAM (simultaneous localization and mapping),也称为CML (Concurrent Mapping and Localization), 即时定位与地图构建，或并发建图与定位。问题可以描述为：将一个机器人放入未知环境中的未知位置，是否有办法让机器人一边逐步描绘出此环境完全的地图，同时一边决定机器人应该往哪个方向行进。例如扫地机器人就是一个很典型的SLAM问题，所谓完全的地图（a consistent map）是指不受障碍行进到房间可进入的每个角落。SLAM最早由Smith、Self和Cheeseman于1988年提出。由于其重要的理论与应用价值，被很多学者认为是实现真正全自主移动机器人的关键。</p>
<p>当你来到一个陌生的环境时，为了迅速熟悉环境并完成自己的任务（比如找饭馆，找旅馆），你应当做以下事情： a.用眼睛观察周围地标如建筑、大树、花坛等，并记住他们的特征（特征提取） b.在自己的脑海中，根据双目获得的信息，把特征地标在三维地图中重建出来（三维重建） c.当自己在行走时，不断获取新的特征地标，并且校正自己头脑中的地图模型（bundle adjustment or EKF） d.根据自己前一段时间行走获得的特征地标，确定自己的位置（trajectory） e.当无意中走了很长一段路的时候，和脑海中的以往地标进行匹配，看一看是否走回了原路（loop-closure detection）。实际这一步可有可无。 以上五步是同时进行的，因此是simultaneous localization and mapping.</p>
</blockquote>
<p>粒子滤波面临的问题</p>
<blockquote>
<p>Although the particle filter algorithm can be used as an effective means to  solve the SLAM problem, there are still some problems in the algorithm.  The main problem is that a large number of samples are needed to closely approximate the posterior probability density of the system. The more  complex the environment the robot faces, the more samples are needed to  describe the posterior probability distribution, and the more complex  the algorithm.</p>
<p>Therefore, an adaptive sampling strategy that can effectively reduce the number of samples is the focus of the algorithm. In addition, the re-sampling  phase can result in loss of sample validity and diversity, leading to  sample depletion. How to maintain the validity and diversity of  particles and overcome the depletion of samples is also re-sampling the  focus of this algorithm.</p>
</blockquote>
<h3 id="马尔可夫链蒙特卡洛方法"><a href="#马尔可夫链蒙特卡洛方法" class="headerlink" title="马尔可夫链蒙特卡洛方法"></a>马尔可夫链蒙特卡洛方法</h3><h4 id="图文解读什么是马尔可夫链蒙特卡罗方法"><a href="#图文解读什么是马尔可夫链蒙特卡罗方法" class="headerlink" title="图文解读什么是马尔可夫链蒙特卡罗方法"></a><a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2017-12-24-6">图文解读什么是马尔可夫链蒙特卡罗方法</a></h4><p>简单地说</p>
<blockquote>
<p>MCMC方法是用来在概率空间，通过随机采样估算兴趣参数的后验分布。</p>
</blockquote>
<img src="https://pic3.zhimg.com/80/v2-77b78405273672540fcf1abfff58f396_720w.jpg" alt="img" style="zoom: 33%;" />

<p>红色的曲线代表后验分布。你可以把它看作先验分布和可能性分布的平均值。由于先验分布较短且分散，所以它反映了人们并不太确定人类的平均身高是多少。同时，可能性在相对较窄的范围内汇总了数据，因此它对真是参数值更加确定。</p>
<p>当先验分布和可能性分布被合并时，数据（由可能性表示）支配了之前那个在巨人堆里长大的人的弱先验信念。尽管那一个体仍然认为人类平均身高比数据告诉他的稍高些，但他最相信的是数据。</p>
<p>存在一些后验分布给出了每个参数值的可能性。但是很难看出完整的分布，也无法用分析解决。于是这就需要MCMC方法了。</p>
<p>MCMC允许我们估计后验分布的形状，以防我们无法直接计算。</p>
<p><strong>马尔可夫链</strong></p>
<blockquote>
<p>举一个更有用的例子。假如你的房子有五个房间，分别是卧室、卫生间、客厅、餐厅和厨房。让我们收集一些数据，假设不管你在任何时候处于任何房间，我们都能推测出你下一个可能进入的房间，例如，如果你在厨房，你将有30%的可能性留在厨房，30%的可能性进入餐厅，20%的可能性进入客厅，10%的可能性进入卧室，然后有10%的可能性去到卫生间。利用每个房间的一组概率，我们可以构建一个“你将去到的房间”链。</p>
<p>如果我们想要预测这个人在离开厨房后会在哪个房间中待一小会儿的概率，那么做一些预测是有用的。但是由于我们的预测只是基于对房间里一个人的观察，所以有理由认为这种预测表现的不会很好。例如，假设一个人从卧室出来后进入了卫生间，那么他更有可能直接回到卧室。但如果是从厨房出来的话，就不一定回到卧室了。所以马尔科夫的成果不一定适用于现实世界。</p>
<p>然而，将马尔可夫链进行数千次迭代后，确实能够长期预测你可能会进入那个房间。更重要的是，这个预测并没有受到这人最初处于哪个房间的影响！简单地说：在某一时间某人处于家里哪个位置并不重要。所以马尔可夫链这个看似在几个时期内对随机变量建模的不合理方法，可以用来计算该变量的长期趋势。</p>
</blockquote>
<h4 id="刘建平MCMC"><a href="#刘建平MCMC" class="headerlink" title="刘建平MCMC"></a><a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6625739.html">刘建平MCMC</a></h4><ol>
<li>蒙特卡洛方法</li>
</ol>
<p>$$<br>不懂 \quad \theta = \int_a^b f(x)dx =  \int_a^b \frac{f(x)}{p(x)}p(x)dx \approx \frac{1}{n}\sum\limits_{i=0}^{n-1}\frac{f(x_i)}{p(x_i)}<br>$$</p>
<ol start="2">
<li><p>接收-拒绝采样</p>
<p>对于概率分布不是常见的分布，一个可行的办法是采用接受-拒绝采样来得到该分布的样本。既然 <em>p</em>(<em>x</em>) 太复杂在程序中没法直接采样，那么我设定一个程序可采样的分布 <em>q</em>(<em>x</em>) 比如高斯分布，然后按照一定的方法拒绝某些样本，以达到接近 <em>p</em>(<em>x</em>) 分布的目的，其中<em>q</em>(<em>x</em>)叫做 proposal distribution。</p>
<p><img src="https://images2015.cnblogs.com/blog/1042406/201703/1042406-20170327143755811-993574578.png" alt="img"></p>
<p>具体采用过程如下，设定一个方便采样的常用概率分布函数 <em>q</em>(<em>x</em>)，以及一个常量 <em>k</em>，使得 <em>p</em>(<em>x</em>) 总在 kq(<em>x</em>) 的下方。如上图。首先，采样得到<em>q</em>(<em>x</em>)的一个样本$z_0$，采样方法如第三节。然后，从均匀分布（0,<em>k</em> <em>q</em>(<em>z</em>0))中采样得到一个值<em>u</em>。如果<em>u</em>落在了上图中的灰色区域，则拒绝这次抽样，否则接受这个样本<em>z</em>0。重复以上过程得到n个接受的样本$z_0,z_1,…z_ {n−1}$, 整个过程中，我们通过一系列的接受拒绝决策来达到用<em>q</em>(<em>x</em>)模拟<em>p</em>(<em>x</em>)概率分布的目的。</p>
</li>
<li><p>马尔可夫链</p>
<blockquote>
<p>　总结下基于马尔科夫链的采样过程：</p>
<p>　1）输入马尔科夫链状态转移矩阵P，设定状态转移次数阈值<em>n</em>1，需要的样本个数<em>n</em>2</p>
<p>　2）从任意简单概率分布采样得到初始状态值<em>x</em>0</p>
<p>　3）for <em>t</em>=0 to n_1+n_2−1: 从条件概率分布<em>P</em>(<em>x</em>|xt)中采样得到样本x_t+1 样本集$(x_{n_1}, x_{n_1+1},…, x_{n_1+n_2-1})$</p>
<p>　即为我们需要的平稳分布对应的样本集。</p>
</blockquote>
<p>如果假定我们可以得到我们需要采样样本的平稳分布所对应的马尔科夫链状态转移矩阵，那么我们就可以用马尔科夫链采样得到我们需要的样本集，进而进行蒙特卡罗模拟。但是一个重要的问题是，随意给定一个平稳分布<em>π</em>,如何得到它所对应的马尔科夫链状态转移矩阵P呢？这是个大问题。我们绕了一圈似乎还是没有解决任意概率分布采样样本集的问题。幸运的是，MCMC采样通过迂回的方式解决了上面这个大问题，我们在下一篇来讨论MCMC的采样，以及它的使用改进版采样: M-H采样和Gibbs采样.</p>
</li>
<li><p>MCMC采样</p>
<blockquote>
<p>　1）输入我们任意选定的马尔科夫链状态转移矩阵<em>Q</em>，平稳分布<em>π</em>(<em>x</em>)，设定状态转移次数阈值<em>n</em>1，需要的样本个数<em>n</em>2</p>
<p>　2）从任意简单概率分布采样得到初始状态值<em>x</em>0</p>
<p>　3）for <em>t</em>=0  to <em>n</em>1+<em>n</em>2−1: </p>
<blockquote>
<p>a) 从条件概率分布<em>Q</em>(<em>x</em>|x_t)中采样得到样本x<br>b) 从均匀分布采样<em>u</em>∼uniform(0,1)<br>c) 如果$u &lt; \alpha(x_t,x_{<em>}) = \pi(x_{</em>})Q(x_{*},x_t)$, 则接受转移x_t→x，即x_t+1=x</p>
<blockquote>
</blockquote>
<p>d) 否则不接受转移，即x_{t+1}=x_t</p>
</blockquote>
<p>　样本集$(x_{n_1}, x_{n_1+1},…, x_{n_1+n_2-1})$即为我们需要的平稳分布对应的样本集。</p>
</blockquote>
<p>但存在收敛慢的情况，就是上面这个$n_1$非常大，这时就轮到 M-H采样出场了。</p>
<p><strong>Q&amp;A:</strong></p>
<blockquote>
<p>平稳分布（或者对应的条件分布）是需要事先知道的，只是很多平稳分布虽然我们知道其分布形式，但是没有好的方法采用这个平稳分布的样本集，所以才需要MCMC。</p>
<p>我们MCMC的目标是不断迭代逐渐达到平稳，使采集到的样本近似符合平稳分布。所以不存在你说的“一开始拿不到平稳分布”的情况。连分布都不知道，是没法用MCMC采样的。</p>
</blockquote>
</li>
<li><p>M-H采样</p>
<p>接收率 $\alpha$ 做了如下改进<br>$$<br>\alpha(i,j) = min{ \frac{\pi(j)Q(j,i)}{\pi(i)Q(i,j)},1}<br>$$</p>
</li>
<li><p>Gibbs采样</p>
<p>但是M-H采样有两个缺点：一是需要计算接受率，在高维时计算量大。并且由于接受率的原因导致算法收敛时间变长。二是有些高维数据，特征的条件概率分布好求，但是特征的联合分布不好求。因此需要一个好的方法来改进M-H采样，这就是我们下面讲到的Gibbs采样。<br>$$<br>P(A \to B) = \pi(x_2^{(B)}|x_1^{(1)});; if; x_1^{(A)} = x_1^{(B)} =x_1^{(1)}\<br>P(A \to C) = \pi(x_1^{(C)}|x_2^{(1)});; if; x_2^{(A)} = x_2^{(C)} =x_2^{(1)}\<br>P(A \to D) = 0;; else<br>$$<br>二维Gibbs采样过程如下</p>
<blockquote>
<p>利用上一节找到的状态转移矩阵，我们就得到了二维Gibbs采样，这个采样需要两个维度之间的条件概率。具体过程如下：</p>
<p>1）输入平稳分布$\pi(x_1,x_2)$，设定状态转移次数阈值$n_1$，需要的样本个数$n_2$</p>
<p>2）随机初始化初始状态值$x_1^{(0)}$和$x_2^{(0)}$</p>
<p>3）for <em>t</em>=0 to $n_1+n_2-1$: </p>
<blockquote>
<p>a) 从条件概率分布$P(x_2|x_1^{(t)})$中采样得到样本$x_2^{t+1}$</p>
<p>b) 从条件概率分布$P(x_1|x_2^{(t+1)})$中采样得到样本$x_1^{(t+1)}$</p>
<p>样本集${(x_1^{(n_1)}, x_2^{(n_1)}), (x_1^{(n_1+1)}, x_2^{(n_1+1)}), …,  (x_1^{(n_1+n_2-1)}, x_2^{(n_1+n_2-1)})}$即为我们需要的平稳分布对应的样本集。</p>
</blockquote>
<p>整个采样过程中，我们通过轮换坐标轴，采样的过程为：</p>
<p>$(x_1^{(1)}, x_2^{(1)}) \to  (x_1^{(1)}, x_2^{(2)}) \to (x_1^{(2)}, x_2^{(2)}) \to … \to (x_1^{(n_1+n_2-1)}, x_2^{(n_1+n_2-1)})$</p>
</blockquote>
<p>多维Gibbs采样过程类似</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/05/06/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" data-id="ckto3u195000720ia4bywdy5z" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Sort学习笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/04/25/Sort%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2021-04-25T07:54:04.593Z" itemprop="datePublished">2021-04-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Sort学习笔记</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42374559/article/details/96032672">参考1</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/HaoBBNuanMM/article/details/85555547">参考2</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/265545749">np.extend_dims</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq757056521/article/details/108789823">np.ma.compress_rows</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/briblue/article/details/91366128">IOU计算原理详解</a></p>
<p>源码中对</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (trk.time_since_update &lt; <span class="number">1</span>) <span class="keyword">and</span> (trk.hit_streak &gt;= self.min_hits <span class="keyword">or</span> self.frame_count &lt;= 		self.min_hits):</span><br><span class="line">    ...</span><br><span class="line"><span class="comment"># remove dead tracklet</span></span><br><span class="line"><span class="keyword">if</span> (trk.time_since_update &gt; self.max_age):</span><br><span class="line">	self.trackers.pop(i)</span><br></pre></td></tr></table></figure>

<p>部分不理解，生命周期？</p>
<p>在函数<code>associate_detections_to_trackers</code>中从<code>matched_indices</code>得到 <code>unmatched_detections</code>, <code>unmatched_trackers</code>没理解。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/04/25/Sort%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" data-id="ckto3u192000220ia0kd41byw" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-车辆运动模型-Kalman滤波" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/04/19/%E8%BD%A6%E8%BE%86%E8%BF%90%E5%8A%A8%E6%A8%A1%E5%9E%8B-Kalman%E6%BB%A4%E6%B3%A2/" class="article-date">
  <time class="dt-published" datetime="2021-04-19T09:27:45.865Z" itemprop="datePublished">2021-04-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>[toc]</p>
<h1 id="车辆模型"><a href="#车辆模型" class="headerlink" title="车辆模型"></a>车辆模型</h1><p>计算控制命令需要车辆的定位信息，底盘信息以及规划信息。</p>
<p>主要关注的信息是</p>
<p>时间、位置、速度、加速度、角速度、位移、航向角、曲率、前轮转角、方向盘转角、刹车、油门、档位。</p>
<p>windows+shift+s 截屏快捷键</p>
<h2 id="单车模型"><a href="#单车模型" class="headerlink" title="单车模型"></a>单车模型</h2><p>单车模型将左/右轮合并为一个点</p>
<p>单车模型示意图</p>
<img src="https://img-blog.csdn.net/2018100817222628?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM5MTQ0NzE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom: 80%;" />



<p>符号说明</p>
<p><img src="https://i.loli.net/2021/08/11/nwepRdjx6UGK3oy.png" alt="微信截图_20210419174115.png"></p>
<p>$\dot{\psi}$ 为角速度。</p>
<p><img src="https://i.loli.net/2021/08/11/FpyolHatcwdJK8j.png" alt="微信截图_20210419180746.png"></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><img src="https://i.loli.net/2021/08/11/O8oXkv5P76pIUm1.png" alt="微信截图_20210419185652.png"></p>
<h1 id="卡尔曼滤波预测原理"><a href="#卡尔曼滤波预测原理" class="headerlink" title="卡尔曼滤波预测原理"></a>卡尔曼滤波预测原理</h1><p><img src="https://img-blog.csdn.net/20170101103814229?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTk5OTk5OTk5OTk5OWQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img"></p>
<p>相关资料：</p>
<ul>
<li>股票预测：卡尔曼滤波、隐马尔可夫模型。 <a target="_blank" rel="noopener" href="https://github.com/rezeroworld/Stock_Forecasting">github地址</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_23981335/article/details/82968422">卡尔曼滤波python实现及相关博文</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013453604/article/details/50301477">卡尔曼滤波的理解以及参数调整</a> 讲的挺不错的。</li>
<li><a target="_blank" rel="noopener" href="http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/">卡尔曼滤波-英文博客 高分推荐</a></li>
</ul>
<p>卡尔曼滤波参数的设置</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/37750839">知乎 卡尔曼滤波中关键参数的调整</a></li>
</ul>
<p>Q值为过程噪声，越小系统越容易收敛，我们对模型预测的值信任度越高；但是太小则容易发散</p>
<p>R值为测量噪声，太小太大都不一定合适。<code>R</code>太大，卡尔曼滤波响应会变慢，因为它对新测量的值的信任度降低；越小系统收敛越快，但过小则容易出现震荡</p>
<p>P 是误差协方差初始值，表示我们对当前预测状态的信任度，它越小说明我们越相信当前预测状态；它的值决定了初始收敛速度，一般开始设一个较小的值以便于获取较快的收敛速度。</p>
<p>卡尔曼滤波的源代码中 $P,Q,R$ 初始化都是对角阵</p>
<h1 id="Quintic-五次-polynomials-planner"><a href="#Quintic-五次-polynomials-planner" class="headerlink" title="Quintic(五次) polynomials planner"></a>Quintic(五次) polynomials planner</h1><h2 id="Quintic-polynomials-for-one-dimensional-robot-motion"><a href="#Quintic-polynomials-for-one-dimensional-robot-motion" class="headerlink" title="Quintic polynomials for one dimensional robot motion"></a>Quintic polynomials for one dimensional robot motion</h2><p>We assume a one-dimensional robot motion $x(t)$ at time $t$ is formulated as a quintic polynomials based on time as follows:</p>
<p>$x(t) = a_0+a_1t+a_2t^2+a_3t^3+a_4t^4+a_5t^5$ –(1)</p>
<p>$a_0, a_1. a_2, a_3, a_4, a_5$ are parameters of the quintic polynomial.</p>
<p>It is assumed that terminal states (start and end) are known as boundary conditions.</p>
<p>Start position, velocity, and acceleration are $x_s, v_s, a_s$ respectively.</p>
<p>End position, velocity, and acceleration are $x_e, v_e, a_e$ respectively.</p>
<p>So, when time is 0.</p>
<p>$x(0) = a_0 = x_s$ – (2)</p>
<p>Then, differentiating the equation (1) with t, </p>
<p>$x’(t) = a_1+2a_2t+3a_3t^2+4a_4t^3+5a_5t^4$ – (3)</p>
<p>So, when time is 0,</p>
<p>$x’(0) = a_1 = v_s$ – (4)</p>
<p>Then, differentiating the equation (3) with t again, </p>
<p>$x’’(t) = 2a_2+6a_3t+12a_4t^2$ – (5)</p>
<p>So, when time is 0,</p>
<p>$x’’(0) = 2a_2 = a_s$ – (6)</p>
<p>so, we can calculate $a_0$, $a_1$, $a_2$ with eq. (2), (4), (6) and boundary conditions.</p>
<p>$a_3, a_4, a_5$ are still unknown in eq(1).</p>
<p>We assume that the end time for a maneuver is $T$, we can get these equations from eq (1), (3), (5):</p>
<p>$x(T)=a_0+a_1T+a_2T^2+a_3T^3+a_4T^4+a_5T^5=x_e$ – (7)</p>
<p>$x’(T)=a_1+2a_2T+3a_3T^2+4a_4T^3+5a_5T^4=v_e$ – (8)</p>
<p>$x’’(T)=2a_2+6a_3T+12a_4T^2+20a_5T^3=a_e$ – (9)</p>
<p>From eq (7), (8), (9), we can calculate $a_3, a_4, a_5$ to solve the linear equations.</p>
<p>$Ax=b$</p>
<p>$\begin{bmatrix} T^3 &amp; T^4 &amp; T^5 \ 3T^2 &amp; 4T^3 &amp; 5T^4 \ 6T &amp; 12T^2 &amp; 20T^3 \end{bmatrix}<br>\begin{bmatrix} a_3\ a_4\ a_5\end{bmatrix}=\begin{bmatrix} x_e-x_s-v_sT-0.5a_sT^2\ v_e-v_s-a_sT\ a_e-a_s\end{bmatrix}$</p>
<p>We can get all unknown parameters now</p>
<h2 id="Quintic-polynomials-for-two-dimensional-robot-motion-x-y"><a href="#Quintic-polynomials-for-two-dimensional-robot-motion-x-y" class="headerlink" title="Quintic polynomials for two dimensional robot motion (x-y)"></a>Quintic polynomials for two dimensional robot motion (x-y)</h2><p>If you use two quintic polynomials along x axis and y axis, you can plan for two dimensional robot motion in x-y plane.</p>
<p>$x(t) = a_0+a_1t+a_2t^2+a_3t^3+a_4t^4+a_5t^5$ –(10)</p>
<p>$y(t) = b_0+b_1t+b_2t^2+b_3t^3+b_4t^4+b_5t^5$ –(11)</p>
<p>It is assumed that terminal states (start and end) are known as boundary conditions.</p>
<p>Start position, orientation, velocity, and acceleration are $x_s, y_s, \theta_s, v_s, a_s$ respectively.</p>
<p>End position, orientation, velocity, and acceleration are $x_e, y_e. \theta_e, v_e, a_e$ respectively.</p>
<p>Each velocity and acceleration boundary condition can be calculated with each orientation.</p>
<p>$v_{xs}=v_scos(\theta_s), v_{ys}=v_ssin(\theta_s)$</p>
<p>$v_{xe}=v_ecos(\theta_e), v_{ye}=v_esin(\theta_e)$</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/04/19/%E8%BD%A6%E8%BE%86%E8%BF%90%E5%8A%A8%E6%A8%A1%E5%9E%8B-Kalman%E6%BB%A4%E6%B3%A2/" data-id="ckto3u197000a20iah99u2jak" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-trajectoryVisualization开发日志" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/04/16/trajectoryVisualization%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/" class="article-date">
  <time class="dt-published" datetime="2021-04-16T06:38:29.476Z" itemprop="datePublished">2021-04-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="开发日志"><a href="#开发日志" class="headerlink" title="开发日志"></a>开发日志</h1><p>完成了数据的可视化程序，程序正常</p>
<h2 id="2021-04-16"><a href="#2021-04-16" class="headerlink" title="2021.04.16"></a>2021.04.16</h2><p>添加稳定性方法，具体内容见 对轨迹问题的思考.md文件</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/04/16/trajectoryVisualization%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/" data-id="ckto3u193000420iad67t2ayp" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/08/09/pcap%E5%8C%85%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95%E7%BD%91%E5%9D%80/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/07/28/%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%AE%B0/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/07/15/2017%E5%B9%B4%E6%9D%A5%E7%9B%B8%E5%85%B3%E7%9A%843D%E8%A7%86%E8%A7%89%E7%82%B9%E4%BA%91%E7%AE%97%E6%B3%95%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/06/16/%E5%86%85%E5%A4%96%E5%8F%82%E6%A0%87%E5%AE%9A/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/06/07/%E9%9A%A7%E9%81%93%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>